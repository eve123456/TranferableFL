nohup: ignoring input



 reg_J_flag =  0
<class 'int'>



 does 0 == 0 ?   True



 reg_J_flag =  False
>>> Arguments:
	             algo : fedavg4
	       batch_size : 64
	clients_per_round : 10
	          dataset : mnist_all_data_1_random_niid
	           device : 0
	              dis : 
	       eval_every : 5
	 finetune_dataset : mnist-m
	  finetune_epochs : 20
	      finetune_lr : 0.01
	      finetune_wd : 0.0
	    ft_batch_size : 1024
	              gpu : True
	      input_shape : (1, 28, 28)
	        lbd_reg_J : 0.0001
	               lr : 0.01
	            model : LeNet
	        noaverage : False
	          noprint : False
	        num_class : 10
	        num_epoch : 10
	        num_round : 200
	       reg_J_flag : False
	             seed : 52
	               wd : 0.0
>>> Read data from:
     ./data/mnist/data/train/all_data_1_random_niid.pkl
     ./data/mnist/data/test/all_data_1_random_niid.pkl
Training model_flag...
Epoch:001, Trn_loss:0.0207, Trn_acc:0.3335, Tst_loss:0.1764, Tst_acc:0.3291
Epoch:002, Trn_loss:0.0212, Trn_acc:0.3650, Tst_loss:0.1736, Tst_acc:0.3677
Epoch:003, Trn_loss:0.0207, Trn_acc:0.3787, Tst_loss:0.1753, Tst_acc:0.3726
Epoch:004, Trn_loss:0.0199, Trn_acc:0.3866, Tst_loss:0.1655, Tst_acc:0.3797
Epoch:005, Trn_loss:0.0194, Trn_acc:0.3884, Tst_loss:0.1661, Tst_acc:0.3804
Epoch:006, Trn_loss:0.0196, Trn_acc:0.3901, Tst_loss:0.1654, Tst_acc:0.3834
Epoch:007, Trn_loss:0.0197, Trn_acc:0.3925, Tst_loss:0.1612, Tst_acc:0.3858
Epoch:008, Trn_loss:0.0194, Trn_acc:0.3907, Tst_loss:0.1685, Tst_acc:0.3838
Epoch:009, Trn_loss:0.0198, Trn_acc:0.3935, Tst_loss:0.1595, Tst_acc:0.3858
Epoch:010, Trn_loss:0.0194, Trn_acc:0.3974, Tst_loss:0.1600, Tst_acc:0.3882
Epoch:011, Trn_loss:0.0185, Trn_acc:0.3904, Tst_loss:0.1605, Tst_acc:0.3856
Epoch:012, Trn_loss:0.0193, Trn_acc:0.3960, Tst_loss:0.1635, Tst_acc:0.3858
Epoch:013, Trn_loss:0.0186, Trn_acc:0.3926, Tst_loss:0.1670, Tst_acc:0.3888
Epoch:014, Trn_loss:0.0195, Trn_acc:0.3912, Tst_loss:0.1658, Tst_acc:0.3835
Epoch:015, Trn_loss:0.0188, Trn_acc:0.3920, Tst_loss:0.1636, Tst_acc:0.3890
Epoch:016, Trn_loss:0.0197, Trn_acc:0.3814, Tst_loss:0.1640, Tst_acc:0.3746
Epoch:017, Trn_loss:0.0192, Trn_acc:0.3959, Tst_loss:0.1629, Tst_acc:0.3888
Epoch:018, Trn_loss:0.0195, Trn_acc:0.3860, Tst_loss:0.1696, Tst_acc:0.3812
Epoch:019, Trn_loss:0.0194, Trn_acc:0.3912, Tst_loss:0.1569, Tst_acc:0.3888
Epoch:020, Trn_loss:0.0191, Trn_acc:0.3918, Tst_loss:0.1598, Tst_acc:0.3891
Finetune done
