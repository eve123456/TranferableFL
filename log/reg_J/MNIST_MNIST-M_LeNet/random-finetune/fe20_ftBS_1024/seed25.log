nohup: ignoring input



 reg_J_flag =  0
<class 'int'>



 does 0 == 0 ?   True



 reg_J_flag =  False
>>> Arguments:
	             algo : fedavg4
	       batch_size : 64
	clients_per_round : 10
	          dataset : mnist_all_data_1_random_niid
	           device : 0
	              dis : 
	       eval_every : 5
	 finetune_dataset : mnist-m
	  finetune_epochs : 20
	      finetune_lr : 0.01
	      finetune_wd : 0.0
	    ft_batch_size : 1024
	              gpu : True
	      input_shape : (1, 28, 28)
	        lbd_reg_J : 0.0001
	               lr : 0.01
	            model : LeNet
	        noaverage : False
	          noprint : False
	        num_class : 10
	        num_epoch : 10
	        num_round : 200
	       reg_J_flag : False
	             seed : 25
	               wd : 0.0
>>> Read data from:
     ./data/mnist/data/train/all_data_1_random_niid.pkl
     ./data/mnist/data/test/all_data_1_random_niid.pkl
Training model_flag...
Epoch:001, Trn_loss:0.0203, Trn_acc:0.3398, Tst_loss:0.1788, Tst_acc:0.3407
Epoch:002, Trn_loss:0.0207, Trn_acc:0.3635, Tst_loss:0.1703, Tst_acc:0.3644
Epoch:003, Trn_loss:0.0198, Trn_acc:0.3750, Tst_loss:0.1691, Tst_acc:0.3746
Epoch:004, Trn_loss:0.0200, Trn_acc:0.3847, Tst_loss:0.1622, Tst_acc:0.3902
Epoch:005, Trn_loss:0.0196, Trn_acc:0.3951, Tst_loss:0.1574, Tst_acc:0.3967
Epoch:006, Trn_loss:0.0198, Trn_acc:0.3969, Tst_loss:0.1604, Tst_acc:0.4012
Epoch:007, Trn_loss:0.0198, Trn_acc:0.3928, Tst_loss:0.1618, Tst_acc:0.3968
Epoch:008, Trn_loss:0.0196, Trn_acc:0.3994, Tst_loss:0.1597, Tst_acc:0.4055
Epoch:009, Trn_loss:0.0187, Trn_acc:0.4027, Tst_loss:0.1638, Tst_acc:0.4048
Epoch:010, Trn_loss:0.0191, Trn_acc:0.4008, Tst_loss:0.1540, Tst_acc:0.4040
Epoch:011, Trn_loss:0.0188, Trn_acc:0.3991, Tst_loss:0.1580, Tst_acc:0.4038
Epoch:012, Trn_loss:0.0188, Trn_acc:0.4011, Tst_loss:0.1642, Tst_acc:0.4042
Epoch:013, Trn_loss:0.0187, Trn_acc:0.4032, Tst_loss:0.1585, Tst_acc:0.4040
Epoch:014, Trn_loss:0.0194, Trn_acc:0.3986, Tst_loss:0.1568, Tst_acc:0.4064
Epoch:015, Trn_loss:0.0184, Trn_acc:0.4035, Tst_loss:0.1610, Tst_acc:0.4111
Epoch:016, Trn_loss:0.0185, Trn_acc:0.3984, Tst_loss:0.1585, Tst_acc:0.4025
Epoch:017, Trn_loss:0.0193, Trn_acc:0.4131, Tst_loss:0.1570, Tst_acc:0.4183
Epoch:018, Trn_loss:0.0189, Trn_acc:0.4013, Tst_loss:0.1551, Tst_acc:0.4014
Epoch:019, Trn_loss:0.0189, Trn_acc:0.3965, Tst_loss:0.1613, Tst_acc:0.4011
Epoch:020, Trn_loss:0.0187, Trn_acc:0.4108, Tst_loss:0.1612, Tst_acc:0.4185
Finetune done
