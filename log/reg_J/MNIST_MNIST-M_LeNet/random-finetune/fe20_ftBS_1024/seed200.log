nohup: ignoring input



 reg_J_flag =  0
<class 'int'>



 does 0 == 0 ?   True



 reg_J_flag =  False
>>> Arguments:
	             algo : fedavg4
	       batch_size : 64
	clients_per_round : 10
	          dataset : mnist_all_data_1_random_niid
	           device : 0
	              dis : 
	       eval_every : 5
	 finetune_dataset : mnist-m
	  finetune_epochs : 20
	      finetune_lr : 0.01
	      finetune_wd : 0.0
	    ft_batch_size : 1024
	              gpu : True
	      input_shape : (1, 28, 28)
	        lbd_reg_J : 0.0001
	               lr : 0.01
	            model : LeNet
	        noaverage : False
	          noprint : False
	        num_class : 10
	        num_epoch : 10
	        num_round : 200
	       reg_J_flag : False
	             seed : 200
	               wd : 0.0
>>> Read data from:
     ./data/mnist/data/train/all_data_1_random_niid.pkl
     ./data/mnist/data/test/all_data_1_random_niid.pkl
Training model_flag...
Epoch:001, Trn_loss:0.0202, Trn_acc:0.3352, Tst_loss:0.1722, Tst_acc:0.3369
Epoch:002, Trn_loss:0.0199, Trn_acc:0.3676, Tst_loss:0.1662, Tst_acc:0.3663
Epoch:003, Trn_loss:0.0189, Trn_acc:0.3985, Tst_loss:0.1571, Tst_acc:0.4026
Epoch:004, Trn_loss:0.0189, Trn_acc:0.4051, Tst_loss:0.1596, Tst_acc:0.4113
Epoch:005, Trn_loss:0.0189, Trn_acc:0.4127, Tst_loss:0.1576, Tst_acc:0.4137
Epoch:006, Trn_loss:0.0182, Trn_acc:0.4221, Tst_loss:0.1569, Tst_acc:0.4258
Epoch:007, Trn_loss:0.0185, Trn_acc:0.4216, Tst_loss:0.1575, Tst_acc:0.4282
Epoch:008, Trn_loss:0.0189, Trn_acc:0.4262, Tst_loss:0.1579, Tst_acc:0.4297
Epoch:009, Trn_loss:0.0184, Trn_acc:0.4253, Tst_loss:0.1505, Tst_acc:0.4281
Epoch:010, Trn_loss:0.0192, Trn_acc:0.4136, Tst_loss:0.1623, Tst_acc:0.4144
Epoch:011, Trn_loss:0.0184, Trn_acc:0.4233, Tst_loss:0.1495, Tst_acc:0.4261
Epoch:012, Trn_loss:0.0190, Trn_acc:0.4348, Tst_loss:0.1526, Tst_acc:0.4382
Epoch:013, Trn_loss:0.0192, Trn_acc:0.4131, Tst_loss:0.1617, Tst_acc:0.4161
Epoch:014, Trn_loss:0.0190, Trn_acc:0.4330, Tst_loss:0.1508, Tst_acc:0.4351
Epoch:015, Trn_loss:0.0189, Trn_acc:0.4362, Tst_loss:0.1515, Tst_acc:0.4368
Epoch:016, Trn_loss:0.0187, Trn_acc:0.4271, Tst_loss:0.1536, Tst_acc:0.4324
Epoch:017, Trn_loss:0.0179, Trn_acc:0.4160, Tst_loss:0.1532, Tst_acc:0.4145
Epoch:018, Trn_loss:0.0177, Trn_acc:0.4267, Tst_loss:0.1453, Tst_acc:0.4268
Epoch:019, Trn_loss:0.0183, Trn_acc:0.4308, Tst_loss:0.1496, Tst_acc:0.4341
Epoch:020, Trn_loss:0.0186, Trn_acc:0.4309, Tst_loss:0.1557, Tst_acc:0.4321
Finetune done
