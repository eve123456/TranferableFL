nohup: ignoring input
Traceback (most recent call last):
  File "/data/shared/eve/TranferableFL/temp_load_test.py", line 4, in <module>
    import numpy as np
ModuleNotFoundError: No module named 'numpy'
nohup: ignoring input
Using device: cuda:0
>>> Arguments:
	             algo : fedavgtl
	            alpha : 13.2316427
	       batch_size : 64
	clients_per_round : 100
	          dataset : mnist_all_data_1_equal_niid
	           device : cuda:0
	              dis : 
	   early_stopping : 10
	       eval_every : 5
	    ft_batch_size : 128
	       ft_dataset : mnist-m
	        ft_epochs : 200
	            ft_lr : 0.001
	            ft_wd : 0.01
	              gpu : True
	      input_shape : (1, 28, 28)
	           last_k : 1
	               lr : 0.01
	            model : lenet
	           n_init : 10
	        noaverage : False
	             noft : False
	          noprint : False
	        num_class : 10
	        num_epoch : 1
	        num_round : 200
	           opt_lr : False
	            reg_J : True
	       reg_J_coef : 0.01
	           repeat : 1
	             seed : 0
	               wd : 0.0

************************************************************************************************************************

uid: 20230919213011
Traceback (most recent call last):
  File "temp_load_test.py", line 268, in <module>
    main()
  File "temp_load_test.py", line 241, in main
    flat_model_params = torch.load(model_path)
  File "/home/pingm/miniconda3/envs/TRANS-FL/lib/python3.7/site-packages/torch/serialization.py", line 699, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/pingm/miniconda3/envs/TRANS-FL/lib/python3.7/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/pingm/miniconda3/envs/TRANS-FL/lib/python3.7/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './models/lenet_mnist_20230915231947.pt'
nohup: ignoring input
Using device: cuda:0
>>> Arguments:
	             algo : fedavgtl
	            alpha : 13.2316427
	       batch_size : 64
	clients_per_round : 100
	          dataset : mnist_all_data_1_equal_niid
	           device : cuda:0
	              dis : 
	   early_stopping : 10
	       eval_every : 5
	    ft_batch_size : 128
	       ft_dataset : mnist-m
	        ft_epochs : 200
	            ft_lr : 0.001
	            ft_wd : 0.01
	              gpu : True
	      input_shape : (1, 28, 28)
	           last_k : 1
	               lr : 0.01
	            model : lenet
	           n_init : 10
	        noaverage : False
	             noft : False
	          noprint : False
	        num_class : 10
	        num_epoch : 1
	        num_round : 200
	           opt_lr : False
	            reg_J : True
	       reg_J_coef : 0.01
	           repeat : 1
	             seed : 0
	               wd : 0.0

************************************************************************************************************************

uid: 20230919213443
>>> Training model_ft
Epoch: 001, Train_loss: 1.2144, Train_acc: 0.6341, Test_loss: 1.1928, Test_acc: 0.6458
Epoch: 006, Train_loss: 1.0397, Train_acc: 0.6878, Test_loss: 1.0230, Test_acc: 0.6964
Epoch: 011, Train_loss: 1.0152, Train_acc: 0.6950, Test_loss: 1.0037, Test_acc: 0.7025
Epoch: 016, Train_loss: 1.0102, Train_acc: 0.6913, Test_loss: 1.0007, Test_acc: 0.6976
Epoch: 021, Train_loss: 1.0048, Train_acc: 0.6982, Test_loss: 0.9945, Test_acc: 0.7030
Epoch: 026, Train_loss: 1.0116, Train_acc: 0.6947, Test_loss: 1.0056, Test_acc: 0.6969
Epoch: 031, Train_loss: 1.0036, Train_acc: 0.7004, Test_loss: 0.9946, Test_acc: 0.7049
Epoch: 036, Train_loss: 1.0004, Train_acc: 0.6994, Test_loss: 0.9951, Test_acc: 0.7051
Epoch: 041, Train_loss: 1.0034, Train_acc: 0.7006, Test_loss: 0.9950, Test_acc: 0.7061
Epoch: 046, Train_loss: 0.9906, Train_acc: 0.7059, Test_loss: 0.9820, Test_acc: 0.7133
Epoch: 051, Train_loss: 0.9931, Train_acc: 0.6989, Test_loss: 0.9852, Test_acc: 0.7084
Fine-tuning early stopped. Model saved at ./models/ft_checkpoints/20230919213443_model_ft.pt.
Model saved at ./models/ft_checkpoints/20230919213443_model_ft.pt.
>>> Fine-tuning done!
model_ft: [0.9905662653646263, 0.7058863409094761, 0.9820352920014757, 0.7132540828796801]
model_ft_test_acc_mean 0.7132540828796801
