nohup: ignoring input
working!
Using device: cuda:0
>>> Arguments:
	             algo : fedavgtl
	            alpha : 13.2316427
	       batch_size : 64
	clients_per_round : 100
	             clip : False
	          dataset : mnist_all_data_1_equal_niid
	           device : cuda:0
	              dis : 
	   early_stopping : 10
	       eval_every : 5
	    ft_batch_size : 128
	       ft_dataset : svhn
	        ft_epochs : 200
	            ft_lr : 0.001
	            ft_wd : 0.01
	              gpu : True
	      input_shape : (1, 28, 28)
	           last_k : 1
	               lr : 0.01
	            model : lenet
	           n_init : 10
	        noaverage : False
	             noft : False
	          noprint : False
	        num_class : 10
	        num_epoch : 1
	        num_round : 10
	           opt_lr : True
	            reg_J : False
	       reg_J_coef : 0.0
	   reg_J_ind_coef : 0.01
	  reg_J_norm_coef : 0.0
	          reg_max : True
	           repeat : 5
	     repeat_epoch : 10
	             seed : 0
	               wd : 0.0
>>> Read data from:
     ./data/mnist/data/all_data_1.pkl
nohup: ignoring input
working!
Using device: cuda:0
>>> Arguments:
	             algo : fedavgtl
	            alpha : 13.2316427
	       batch_size : 64
	clients_per_round : 100
	             clip : False
	          dataset : mnist_all_data_1_equal_niid
	           device : cuda:0
	              dis : 
	   early_stopping : 10
	       eval_every : 5
	    ft_batch_size : 128
	       ft_dataset : svhn
	        ft_epochs : 200
	            ft_lr : 0.001
	            ft_wd : 0.01
	              gpu : True
	      input_shape : (1, 28, 28)
	           last_k : 1
	               lr : 0.01
	            model : lenet
	           n_init : 10
	        noaverage : False
	             noft : False
	          noprint : False
	        num_class : 10
	        num_epoch : 1
	        num_round : 10
	           opt_lr : True
	            reg_J : False
	       reg_J_coef : 0.0
	   reg_J_ind_coef : 0.01
	  reg_J_norm_coef : 0.0
	          reg_max : True
	           repeat : 5
	     repeat_epoch : 10
	             seed : 0
	               wd : 0.0
>>> Get SVHN data.

************************************************************************************************************************

uid: 20231002160447
FL pretrained model will be saved at ./models/lenet_mnist_20231002160447.pt
Traceback (most recent call last):
  File "main_mnist_mnist_m.py", line 412, in <module>
    main()
  File "main_mnist_mnist_m.py", line 339, in main
    trainer = trainer_class(options, all_data_info, model_path)
NameError: name 'all_data_info' is not defined
nohup: ignoring input
working!
Using device: cuda:0
>>> Arguments:
	             algo : fedavgtl
	            alpha : 13.2316427
	       batch_size : 64
	clients_per_round : 100
	             clip : False
	          dataset : mnist_all_data_1_equal_niid
	           device : cuda:0
	              dis : 
	   early_stopping : 10
	       eval_every : 5
	    ft_batch_size : 128
	       ft_dataset : svhn
	        ft_epochs : 200
	            ft_lr : 0.001
	            ft_wd : 0.01
	              gpu : True
	      input_shape : (1, 28, 28)
	           last_k : 1
	               lr : 0.01
	            model : lenet
	           n_init : 10
	        noaverage : False
	             noft : False
	          noprint : False
	        num_class : 10
	        num_epoch : 1
	        num_round : 10
	           opt_lr : True
	            reg_J : False
	       reg_J_coef : 0.0
	   reg_J_ind_coef : 0.01
	  reg_J_norm_coef : 0.0
	          reg_max : True
	           repeat : 5
	     repeat_epoch : 10
	             seed : 0
	               wd : 0.0
>>> Get SVHN data.

************************************************************************************************************************

uid: 20231002160531
>>> Training model_random
Epoch: 001, Train_loss: 2.2365, Train_acc: 0.1892, Test_loss: 2.2248, Test_acc: 0.1959
Epoch: 006, Train_loss: 2.2365, Train_acc: 0.1892, Test_loss: 2.2245, Test_acc: 0.1959
Epoch: 011, Train_loss: 2.2369, Train_acc: 0.1892, Test_loss: 2.2258, Test_acc: 0.1959
Fine-tuning early stopped. Model saved at ./models/ft_checkpoints/20231002160531_model_random.pt.
Model saved at ./models/ft_checkpoints/20231002160531_model_random.pt.
>>> Fine-tuning done!

************************************************************************************************************************

uid: 20231002160753
>>> Training model_random
Epoch: 001, Train_loss: 2.2370, Train_acc: 0.1892, Test_loss: 2.2260, Test_acc: 0.1959
Epoch: 006, Train_loss: 2.2367, Train_acc: 0.1892, Test_loss: 2.2249, Test_acc: 0.1959
Epoch: 011, Train_loss: 2.2367, Train_acc: 0.1892, Test_loss: 2.2250, Test_acc: 0.1959
Fine-tuning early stopped. Model saved at ./models/ft_checkpoints/20231002160753_model_random.pt.
Model saved at ./models/ft_checkpoints/20231002160753_model_random.pt.
>>> Fine-tuning done!

************************************************************************************************************************

uid: 20231002161019
>>> Training model_random
Epoch: 001, Train_loss: 2.2376, Train_acc: 0.1892, Test_loss: 2.2258, Test_acc: 0.1959
Epoch: 006, Train_loss: 2.2370, Train_acc: 0.1892, Test_loss: 2.2257, Test_acc: 0.1959
Epoch: 011, Train_loss: 2.2368, Train_acc: 0.1892, Test_loss: 2.2248, Test_acc: 0.1959
Epoch: 016, Train_loss: 2.2368, Train_acc: 0.1892, Test_loss: 2.2254, Test_acc: 0.1959
Epoch: 021, Train_loss: 2.2368, Train_acc: 0.1892, Test_loss: 2.2251, Test_acc: 0.1959
Epoch: 026, Train_loss: 2.2366, Train_acc: 0.1892, Test_loss: 2.2246, Test_acc: 0.1959
Fine-tuning early stopped. Model saved at ./models/ft_checkpoints/20231002161019_model_random.pt.
Model saved at ./models/ft_checkpoints/20231002161019_model_random.pt.
>>> Fine-tuning done!

************************************************************************************************************************

uid: 20231002161511
>>> Training model_random
Epoch: 001, Train_loss: 2.2371, Train_acc: 0.1892, Test_loss: 2.2256, Test_acc: 0.1959
Epoch: 006, Train_loss: 2.2369, Train_acc: 0.1892, Test_loss: 2.2255, Test_acc: 0.1959
Epoch: 011, Train_loss: 2.2370, Train_acc: 0.1892, Test_loss: 2.2255, Test_acc: 0.1959
Fine-tuning early stopped. Model saved at ./models/ft_checkpoints/20231002161511_model_random.pt.
Model saved at ./models/ft_checkpoints/20231002161511_model_random.pt.
>>> Fine-tuning done!

************************************************************************************************************************

uid: 20231002161738
>>> Training model_random
Epoch: 001, Train_loss: 2.2369, Train_acc: 0.1892, Test_loss: 2.2258, Test_acc: 0.1959
Epoch: 006, Train_loss: 2.2375, Train_acc: 0.1892, Test_loss: 2.2260, Test_acc: 0.1959
Epoch: 011, Train_loss: 2.2371, Train_acc: 0.1892, Test_loss: 2.2257, Test_acc: 0.1959
Fine-tuning early stopped. Model saved at ./models/ft_checkpoints/20231002161738_model_random.pt.
Model saved at ./models/ft_checkpoints/20231002161738_model_random.pt.
>>> Fine-tuning done!
model_random_test_acc_mean 0.1958743085433313
