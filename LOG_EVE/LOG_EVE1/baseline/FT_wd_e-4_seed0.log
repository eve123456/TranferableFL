nohup: ignoring input
Using device: cuda:0
>>> Arguments:
	             algo : fedavgtl
	            alpha : 13.2316427
	       batch_size : 64
	clients_per_round : 100
	          dataset : mnist_all_data_1_equal_niid
	           device : cuda:0
	              dis : 
	   early_stopping : 10
	       eval_every : 5
	    ft_batch_size : 128
	       ft_dataset : mnist-m
	        ft_epochs : 200
	            ft_lr : 0.001
	            ft_wd : 0.0001
	              gpu : True
	      input_shape : (1, 28, 28)
	           last_k : 1
	               lr : 0.01
	            model : lenet
	           n_init : 10
	        noaverage : False
	             noft : False
	          noprint : False
	        num_class : 10
	        num_epoch : 1
	        num_round : 200
	           opt_lr : False
	            reg_J : True
	       reg_J_coef : 0.01
	           repeat : 1
	             seed : 0
	               wd : 0.0

************************************************************************************************************************

uid: 20230925110821
>>> Training model_ft
Epoch: 001, Train_loss: 1.1068, Train_acc: 0.6559, Test_loss: 1.0845, Test_acc: 0.6696
Epoch: 006, Train_loss: 0.8438, Train_acc: 0.7383, Test_loss: 0.8423, Test_acc: 0.7405
Epoch: 011, Train_loss: 0.7860, Train_acc: 0.7556, Test_loss: 0.7947, Test_acc: 0.7564
Epoch: 016, Train_loss: 0.7432, Train_acc: 0.7665, Test_loss: 0.7635, Test_acc: 0.7617
Epoch: 021, Train_loss: 0.7204, Train_acc: 0.7747, Test_loss: 0.7515, Test_acc: 0.7681
Epoch: 026, Train_loss: 0.7147, Train_acc: 0.7726, Test_loss: 0.7536, Test_acc: 0.7655
Epoch: 031, Train_loss: 0.6932, Train_acc: 0.7799, Test_loss: 0.7412, Test_acc: 0.7705
Epoch: 036, Train_loss: 0.6781, Train_acc: 0.7840, Test_loss: 0.7314, Test_acc: 0.7707
Epoch: 041, Train_loss: 0.6721, Train_acc: 0.7873, Test_loss: 0.7304, Test_acc: 0.7731
Epoch: 046, Train_loss: 0.6518, Train_acc: 0.7908, Test_loss: 0.7147, Test_acc: 0.7774
Epoch: 051, Train_loss: 0.6536, Train_acc: 0.7882, Test_loss: 0.7263, Test_acc: 0.7781
Epoch: 056, Train_loss: 0.6536, Train_acc: 0.7896, Test_loss: 0.7337, Test_acc: 0.7730
Epoch: 061, Train_loss: 0.6365, Train_acc: 0.7968, Test_loss: 0.7168, Test_acc: 0.7756
Epoch: 066, Train_loss: 0.6257, Train_acc: 0.7977, Test_loss: 0.7103, Test_acc: 0.7792
Epoch: 071, Train_loss: 0.6212, Train_acc: 0.7991, Test_loss: 0.7116, Test_acc: 0.7784
Epoch: 076, Train_loss: 0.6133, Train_acc: 0.8013, Test_loss: 0.7055, Test_acc: 0.7779
Epoch: 081, Train_loss: 0.6257, Train_acc: 0.7954, Test_loss: 0.7191, Test_acc: 0.7715
Fine-tuning early stopped. Model saved at ./models/ft_checkpoints/20230925110821_model_ft.pt.
Model saved at ./models/ft_checkpoints/20230925110821_model_ft.pt.
>>> Fine-tuning done!
model_ft: [0.6133470943189432, 0.8012576058032914, 0.7055114916650047, 0.7779135651594268]
model_ft_test_acc_mean 0.7779135651594268
