nohup: ignoring input
working!
check why cannot sync
Using device: cuda:0
>>> Arguments:
	             algo : fedavgtl
	            alpha : 13.2316427
	       batch_size : 64
	clients_per_round : 100
	             clip : False
	          dataset : mnist_all_data_1_equal_niid
	           device : cuda:0
	              dis : 
	   early_stopping : 10
	       eval_every : 5
	    ft_batch_size : 128
	       ft_dataset : mnist-m
	        ft_epochs : 200
	            ft_lr : 0.001
	            ft_wd : 0.0001
	              gpu : True
	      input_shape : (1, 28, 28)
	           last_k : 1
	               lr : 0.01
	            model : lenet
	           n_init : 1
	        noaverage : False
	             noft : False
	          noprint : False
	        num_class : 10
	        num_epoch : 1
	        num_round : 200
	           opt_lr : True
	            reg_J : False
	       reg_J_coef : 0.0
	   reg_J_ind_coef : 0.0001
	  reg_J_norm_coef : 0.0
	          reg_max : True
	           repeat : 1
	     repeat_epoch : 10
	             seed : 0
	               wd : 0.0
>>> Read data from:
     ./data/mnist/data/all_data_1.pkl
>>> The estimate of constant alpha is 13.2316427.
>>> Read data from:
     ./data/mnist/data/train/all_data_1_equal_niid.pkl
     ./data/mnist/data/test/all_data_1_equal_niid.pkl

************************************************************************************************************************

uid: 20230928000640
FL pretrained model will be saved at ./models/lenet_mnist_20230928000640.pt
>>> Use gpu on device cuda:0
>>> Model statistic per layer
LeNet_MNIST(
  286.12 KMac, 100.000% MACs, 
  (conv1): Conv2d(89.856 KMac, 31.405% MACs, 1, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(154.624 KMac, 54.042% MACs, 6, 16, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(30.72 KMac, 10.737% MACs, in_features=256, out_features=120, bias=True)
  (fc2): Linear(10.08 KMac, 3.523% MACs, in_features=120, out_features=84, bias=True)
  (fc3): Linear(840.0 Mac, 0.294% MACs, in_features=84, out_features=10, bias=True)
)
>>> Activate a worker for training
>>> Initialize 100 clients in total
>>> Weigh updates by simple average
>>> Select 100 clients per round 


>>> Round:    0 / Acc: 6.720% / Loss: 2.3053 /Time: 5.13s
======================================================================================================

= Test = round: 0 / acc: 6.700% / loss: 2.3051 / Time: 1.01s
======================================================================================================

round 0: local lr = 0.01
round 1: local lr = 0.0098822470754385, norm_avg_grad = 0.16650289297103882, avg_norm_grad = 1.2733631134033203,                  max_norm_grad = 1.4509351253509521
round 2: local lr = 0.009785334579646587, norm_avg_grad = 0.18147873878479004, avg_norm_grad = 1.4016393423080444,                  max_norm_grad = 1.6003007888793945
round 3: local lr = 0.009624117985367775, norm_avg_grad = 0.20242005586624146, avg_norm_grad = 1.589566946029663,                  max_norm_grad = 1.8427380323410034
round 4: local lr = 0.009379817172884941, norm_avg_grad = 0.23244664072990417, avg_norm_grad = 1.8729021549224854,                  max_norm_grad = 2.2119603157043457

>>> Round:    5 / Acc: 10.015% / Loss: 2.2844 /Time: 4.39s
======================================================================================================

= Test = round: 5 / acc: 9.590% / loss: 2.2854 / Time: 0.86s
======================================================================================================

round 5: local lr = 0.008938506245613098, norm_avg_grad = 0.2734321653842926, avg_norm_grad = 2.3119096755981445,                  max_norm_grad = 2.7747883796691895
round 6: local lr = 0.008657357655465603, norm_avg_grad = 0.34617048501968384, avg_norm_grad = 3.02197527885437,                  max_norm_grad = 3.6639580726623535
round 7: local lr = 0.008313151076436043, norm_avg_grad = 0.4698927104473114, avg_norm_grad = 4.271882057189941,                  max_norm_grad = 5.236673831939697
round 8: local lr = 0.007870598696172237, norm_avg_grad = 0.655188262462616, avg_norm_grad = 6.291360378265381,                  max_norm_grad = 7.661530017852783
round 9: local lr = 0.006837824359536171, norm_avg_grad = 0.8055595755577087, avg_norm_grad = 8.903605461120605,                  max_norm_grad = 10.796995162963867

>>> Round:   10 / Acc: 26.504% / Loss: 2.1891 /Time: 4.51s
======================================================================================================

= Test = round: 10 / acc: 25.990% / loss: 2.1893 / Time: 0.81s
======================================================================================================

round 10: local lr = 0.006353347562253475, norm_avg_grad = 0.961940586566925, avg_norm_grad = 11.442788124084473,                  max_norm_grad = 13.869438171386719
round 11: local lr = 0.0062217409722507, norm_avg_grad = 1.1340495347976685, avg_norm_grad = 13.775466918945312,                  max_norm_grad = 16.698646545410156
round 12: local lr = 0.007018322590738535, norm_avg_grad = 1.4517885446548462, avg_norm_grad = 15.633501052856445,                  max_norm_grad = 19.13457489013672
round 13: local lr = 0.0073093995451927185, norm_avg_grad = 1.5442121028900146, avg_norm_grad = 15.966564178466797,                  max_norm_grad = 19.554946899414062
round 14: local lr = 0.007834583520889282, norm_avg_grad = 1.6578888893127441, avg_norm_grad = 15.99284553527832,                  max_norm_grad = 19.57908058166504

>>> Round:   15 / Acc: 50.304% / Loss: 2.0350 /Time: 4.73s
======================================================================================================

= Test = round: 15 / acc: 51.170% / loss: 2.0256 / Time: 0.84s
======================================================================================================

round 15: local lr = 0.007560218684375286, norm_avg_grad = 1.5445188283920288, avg_norm_grad = 15.439920425415039,                  max_norm_grad = 18.911218643188477
round 16: local lr = 0.007678195834159851, norm_avg_grad = 1.5850986242294312, avg_norm_grad = 15.6021089553833,                  max_norm_grad = 18.999420166015625
round 17: local lr = 0.00834111962467432, norm_avg_grad = 1.70431649684906, avg_norm_grad = 15.442304611206055,                  max_norm_grad = 18.902629852294922
round 18: local lr = 0.008505184203386307, norm_avg_grad = 1.6738629341125488, avg_norm_grad = 14.873815536499023,                  max_norm_grad = 18.23573112487793
round 19: local lr = 0.008098847232758999, norm_avg_grad = 1.574615240097046, avg_norm_grad = 14.693913459777832,                  max_norm_grad = 18.049728393554688

>>> Round:   20 / Acc: 60.600% / Loss: 1.8184 /Time: 5.14s
======================================================================================================

= Test = round: 20 / acc: 62.090% / loss: 1.7991 / Time: 0.91s
======================================================================================================

round 20: local lr = 0.008081668056547642, norm_avg_grad = 1.6005196571350098, avg_norm_grad = 14.967394828796387,                  max_norm_grad = 18.272748947143555
round 21: local lr = 0.008209976367652416, norm_avg_grad = 1.6408555507659912, avg_norm_grad = 15.104788780212402,                  max_norm_grad = 18.47406578063965
round 22: local lr = 0.008585583418607712, norm_avg_grad = 1.6953667402267456, avg_norm_grad = 14.923821449279785,                  max_norm_grad = 18.420276641845703
round 23: local lr = 0.008181310258805752, norm_avg_grad = 1.5855048894882202, avg_norm_grad = 14.646402359008789,                  max_norm_grad = 18.154258728027344
round 24: local lr = 0.008358410559594631, norm_avg_grad = 1.640674352645874, avg_norm_grad = 14.834909439086914,                  max_norm_grad = 18.71992301940918

>>> Round:   25 / Acc: 66.716% / Loss: 1.5534 /Time: 5.13s
======================================================================================================

= Test = round: 25 / acc: 68.600% / loss: 1.5251 / Time: 0.89s
======================================================================================================

round 25: local lr = 0.008558630011975765, norm_avg_grad = 1.6630421876907349, avg_norm_grad = 14.685381889343262,                  max_norm_grad = 18.40829849243164
round 26: local lr = 0.007960285060107708, norm_avg_grad = 1.5299265384674072, avg_norm_grad = 14.525402069091797,                  max_norm_grad = 18.24001693725586
round 27: local lr = 0.007805477362126112, norm_avg_grad = 1.5168768167495728, avg_norm_grad = 14.6871337890625,                  max_norm_grad = 18.53064727783203
round 28: local lr = 0.008138058707118034, norm_avg_grad = 1.586288332939148, avg_norm_grad = 14.731517791748047,                  max_norm_grad = 18.99864959716797
round 29: local lr = 0.008802054449915886, norm_avg_grad = 1.6883482933044434, avg_norm_grad = 14.496535301208496,                  max_norm_grad = 18.798095703125

>>> Round:   30 / Acc: 69.878% / Loss: 1.3126 /Time: 4.95s
======================================================================================================

= Test = round: 30 / acc: 71.470% / loss: 1.2777 / Time: 1.02s
======================================================================================================

round 30: local lr = 0.009089882485568523, norm_avg_grad = 1.6928871870040894, avg_norm_grad = 14.075244903564453,                  max_norm_grad = 18.073930740356445
round 31: local lr = 0.008948244154453278, norm_avg_grad = 1.6113195419311523, avg_norm_grad = 13.60912036895752,                  max_norm_grad = 17.951438903808594
round 32: local lr = 0.009355751797556877, norm_avg_grad = 1.6736263036727905, avg_norm_grad = 13.519667625427246,                  max_norm_grad = 18.273067474365234
round 33: local lr = 0.008931569755077362, norm_avg_grad = 1.5653762817382812, avg_norm_grad = 13.245768547058105,                  max_norm_grad = 17.844402313232422
round 34: local lr = 0.008425424806773663, norm_avg_grad = 1.4765359163284302, avg_norm_grad = 13.244587898254395,                  max_norm_grad = 18.091053009033203

>>> Round:   35 / Acc: 72.745% / Loss: 1.1032 /Time: 5.47s
======================================================================================================

= Test = round: 35 / acc: 74.040% / loss: 1.0658 / Time: 1.07s
======================================================================================================

round 35: local lr = 0.008688163943588734, norm_avg_grad = 1.5377217531204224, avg_norm_grad = 13.376299858093262,                  max_norm_grad = 18.423709869384766
round 36: local lr = 0.008891189470887184, norm_avg_grad = 1.5480562448501587, avg_norm_grad = 13.158702850341797,                  max_norm_grad = 18.503231048583984
round 37: local lr = 0.009226365014910698, norm_avg_grad = 1.578096866607666, avg_norm_grad = 12.926746368408203,                  max_norm_grad = 18.518957138061523
round 38: local lr = 0.008716994896531105, norm_avg_grad = 1.4693481922149658, avg_norm_grad = 12.7392578125,                  max_norm_grad = 18.202329635620117
round 39: local lr = 0.008898336440324783, norm_avg_grad = 1.4844186305999756, avg_norm_grad = 12.607640266418457,                  max_norm_grad = 18.29283905029297

>>> Round:   40 / Acc: 74.319% / Loss: 0.9613 /Time: 5.28s
======================================================================================================

= Test = round: 40 / acc: 75.680% / loss: 0.9250 / Time: 1.18s
======================================================================================================

round 40: local lr = 0.009697634726762772, norm_avg_grad = 1.607216477394104, avg_norm_grad = 12.525490760803223,                  max_norm_grad = 18.599998474121094
round 41: local lr = 0.008990788832306862, norm_avg_grad = 1.4365044832229614, avg_norm_grad = 12.075230598449707,                  max_norm_grad = 17.627649307250977
round 42: local lr = 0.009044332429766655, norm_avg_grad = 1.4504977464675903, avg_norm_grad = 12.120673179626465,                  max_norm_grad = 17.71272087097168
round 43: local lr = 0.007977086119353771, norm_avg_grad = 1.2632237672805786, avg_norm_grad = 11.968018531799316,                  max_norm_grad = 17.366506576538086
round 44: local lr = 0.008711540140211582, norm_avg_grad = 1.410042405128479, avg_norm_grad = 12.232731819152832,                  max_norm_grad = 18.36820411682129

>>> Round:   45 / Acc: 76.179% / Loss: 0.8474 /Time: 5.19s
======================================================================================================

= Test = round: 45 / acc: 77.500% / loss: 0.8121 / Time: 1.06s
======================================================================================================

round 45: local lr = 0.008563603274524212, norm_avg_grad = 1.373552918434143, avg_norm_grad = 12.122021675109863,                  max_norm_grad = 18.274911880493164
round 46: local lr = 0.008922895416617393, norm_avg_grad = 1.4177515506744385, avg_norm_grad = 12.008272171020508,                  max_norm_grad = 18.469980239868164
round 47: local lr = 0.009163174778223038, norm_avg_grad = 1.4269126653671265, avg_norm_grad = 11.76894760131836,                  max_norm_grad = 18.297012329101562
round 48: local lr = 0.009209944866597652, norm_avg_grad = 1.401917576789856, avg_norm_grad = 11.504074096679688,                  max_norm_grad = 17.924774169921875
round 49: local lr = 0.00857487041503191, norm_avg_grad = 1.2889271974563599, avg_norm_grad = 11.360227584838867,                  max_norm_grad = 17.57148551940918

>>> Round:   50 / Acc: 77.520% / Loss: 0.7740 /Time: 5.13s
======================================================================================================

= Test = round: 50 / acc: 78.860% / loss: 0.7404 / Time: 0.96s
======================================================================================================

round 50: local lr = 0.008030419237911701, norm_avg_grad = 1.215121865272522, avg_norm_grad = 11.435833930969238,                  max_norm_grad = 17.604455947875977
round 51: local lr = 0.008473658934235573, norm_avg_grad = 1.2953999042510986, avg_norm_grad = 11.5536470413208,                  max_norm_grad = 18.089736938476562
round 52: local lr = 0.008841332048177719, norm_avg_grad = 1.337486982345581, avg_norm_grad = 11.432944297790527,                  max_norm_grad = 17.998470306396484
round 53: local lr = 0.008488777093589306, norm_avg_grad = 1.2591180801391602, avg_norm_grad = 11.210049629211426,                  max_norm_grad = 17.451913833618164
round 54: local lr = 0.008987214416265488, norm_avg_grad = 1.325540542602539, avg_norm_grad = 11.14690113067627,                  max_norm_grad = 17.486248016357422

>>> Round:   55 / Acc: 78.579% / Loss: 0.7201 /Time: 5.66s
======================================================================================================

= Test = round: 55 / acc: 79.790% / loss: 0.6875 / Time: 1.07s
======================================================================================================

round 55: local lr = 0.008768635801970959, norm_avg_grad = 1.2799341678619385, avg_norm_grad = 11.031683921813965,                  max_norm_grad = 17.50507926940918
round 56: local lr = 0.008851120248436928, norm_avg_grad = 1.2915644645690918, avg_norm_grad = 11.02818489074707,                  max_norm_grad = 17.55754852294922
round 57: local lr = 0.00956712756305933, norm_avg_grad = 1.3813167810440063, avg_norm_grad = 10.91183853149414,                  max_norm_grad = 17.69309425354004
round 58: local lr = 0.008480608463287354, norm_avg_grad = 1.193963646888733, avg_norm_grad = 10.640212059020996,                  max_norm_grad = 16.983705520629883
round 59: local lr = 0.008822725154459476, norm_avg_grad = 1.2475781440734863, avg_norm_grad = 10.68688678741455,                  max_norm_grad = 17.262287139892578

>>> Round:   60 / Acc: 79.795% / Loss: 0.6752 /Time: 4.68s
======================================================================================================

= Test = round: 60 / acc: 80.840% / loss: 0.6438 / Time: 0.83s
======================================================================================================

round 60: local lr = 0.007869747467339039, norm_avg_grad = 1.1046473979949951, avg_norm_grad = 10.608380317687988,                  max_norm_grad = 16.78095817565918
round 61: local lr = 0.0069311028346419334, norm_avg_grad = 0.9859795570373535, avg_norm_grad = 10.75107192993164,                  max_norm_grad = 16.600296020507812
round 62: local lr = 0.006989062763750553, norm_avg_grad = 1.0128108263015747, avg_norm_grad = 10.952054977416992,                  max_norm_grad = 17.021331787109375
round 63: local lr = 0.006641589105129242, norm_avg_grad = 0.9683114290237427, avg_norm_grad = 11.018672943115234,                  max_norm_grad = 17.270198822021484
round 64: local lr = 0.007589430082589388, norm_avg_grad = 1.1189889907836914, avg_norm_grad = 11.14301872253418,                  max_norm_grad = 17.896684646606445

>>> Round:   65 / Acc: 80.762% / Loss: 0.6316 /Time: 4.57s
======================================================================================================

= Test = round: 65 / acc: 81.940% / loss: 0.6005 / Time: 0.81s
======================================================================================================

round 65: local lr = 0.006737374234944582, norm_avg_grad = 0.9773950576782227, avg_norm_grad = 10.963915824890137,                  max_norm_grad = 17.42447280883789
round 66: local lr = 0.007453723344951868, norm_avg_grad = 1.0924208164215088, avg_norm_grad = 11.076508522033691,                  max_norm_grad = 17.780229568481445
round 67: local lr = 0.007734248414635658, norm_avg_grad = 1.1184372901916504, avg_norm_grad = 10.928982734680176,                  max_norm_grad = 17.807863235473633
round 68: local lr = 0.008207975886762142, norm_avg_grad = 1.1746482849121094, avg_norm_grad = 10.815783500671387,                  max_norm_grad = 17.697349548339844
round 69: local lr = 0.0073861777782440186, norm_avg_grad = 1.0380504131317139, avg_norm_grad = 10.621477127075195,                  max_norm_grad = 16.97669792175293

>>> Round:   70 / Acc: 81.439% / Loss: 0.6077 /Time: 5.11s
======================================================================================================

= Test = round: 70 / acc: 82.310% / loss: 0.5770 / Time: 0.93s
======================================================================================================

round 70: local lr = 0.007128133438527584, norm_avg_grad = 1.003296971321106, avg_norm_grad = 10.637507438659668,                  max_norm_grad = 16.94766616821289
round 71: local lr = 0.007180704269558191, norm_avg_grad = 1.0156188011169434, avg_norm_grad = 10.689315795898438,                  max_norm_grad = 16.943378448486328
round 72: local lr = 0.0067669362761080265, norm_avg_grad = 0.9585891366004944, avg_norm_grad = 10.705985069274902,                  max_norm_grad = 16.873910903930664
round 73: local lr = 0.007515050005167723, norm_avg_grad = 1.071458101272583, avg_norm_grad = 10.775303840637207,                  max_norm_grad = 17.255163192749023
round 74: local lr = 0.007152223493903875, norm_avg_grad = 1.0123624801635742, avg_norm_grad = 10.69747257232666,                  max_norm_grad = 17.158031463623047

>>> Round:   75 / Acc: 82.192% / Loss: 0.5821 /Time: 5.11s
======================================================================================================

= Test = round: 75 / acc: 83.290% / loss: 0.5517 / Time: 0.89s
======================================================================================================

round 75: local lr = 0.007136676460504532, norm_avg_grad = 1.010936975479126, avg_norm_grad = 10.705680847167969,                  max_norm_grad = 17.1398868560791
round 76: local lr = 0.007577052339911461, norm_avg_grad = 1.0782538652420044, avg_norm_grad = 10.754914283752441,                  max_norm_grad = 17.231754302978516
round 77: local lr = 0.00769719947129488, norm_avg_grad = 1.0838642120361328, avg_norm_grad = 10.642125129699707,                  max_norm_grad = 17.329744338989258
round 78: local lr = 0.007571754045784473, norm_avg_grad = 1.0569654703140259, avg_norm_grad = 10.549952507019043,                  max_norm_grad = 17.216768264770508
round 79: local lr = 0.005899141076952219, norm_avg_grad = 0.8144957423210144, avg_norm_grad = 10.434850692749023,                  max_norm_grad = 16.215417861938477

>>> Round:   80 / Acc: 82.915% / Loss: 0.5610 /Time: 5.24s
======================================================================================================

= Test = round: 80 / acc: 83.920% / loss: 0.5304 / Time: 1.00s
======================================================================================================

round 80: local lr = 0.005733161699026823, norm_avg_grad = 0.8003802299499512, avg_norm_grad = 10.550872802734375,                  max_norm_grad = 16.24746322631836
round 81: local lr = 0.006136635318398476, norm_avg_grad = 0.8639613389968872, avg_norm_grad = 10.640210151672363,                  max_norm_grad = 16.499670028686523
round 82: local lr = 0.006127214524894953, norm_avg_grad = 0.8626867532730103, avg_norm_grad = 10.640848159790039,                  max_norm_grad = 16.70964241027832
round 83: local lr = 0.005941013339906931, norm_avg_grad = 0.840534508228302, avg_norm_grad = 10.692548751831055,                  max_norm_grad = 17.0163516998291
round 84: local lr = 0.006396779790520668, norm_avg_grad = 0.9100464582443237, avg_norm_grad = 10.751978874206543,                  max_norm_grad = 17.333566665649414

>>> Round:   85 / Acc: 83.423% / Loss: 0.5430 /Time: 4.87s
======================================================================================================

= Test = round: 85 / acc: 84.390% / loss: 0.5129 / Time: 0.97s
======================================================================================================

round 85: local lr = 0.00682001793757081, norm_avg_grad = 0.9730154275894165, avg_norm_grad = 10.782523155212402,                  max_norm_grad = 17.315692901611328
round 86: local lr = 0.007266027387231588, norm_avg_grad = 1.0291634798049927, avg_norm_grad = 10.704676628112793,                  max_norm_grad = 17.495084762573242
round 87: local lr = 0.006875351537019014, norm_avg_grad = 0.9565317034721375, avg_norm_grad = 10.514549255371094,                  max_norm_grad = 17.06258201599121
round 88: local lr = 0.005887359846383333, norm_avg_grad = 0.8121728301048279, avg_norm_grad = 10.425912857055664,                  max_norm_grad = 16.67152214050293
round 89: local lr = 0.006390398368239403, norm_avg_grad = 0.8867616057395935, avg_norm_grad = 10.487336158752441,                  max_norm_grad = 16.915184020996094

>>> Round:   90 / Acc: 83.812% / Loss: 0.5290 /Time: 5.36s
======================================================================================================

= Test = round: 90 / acc: 84.800% / loss: 0.4985 / Time: 0.84s
======================================================================================================

round 90: local lr = 0.007000830490142107, norm_avg_grad = 0.9740142226219177, avg_norm_grad = 10.514822006225586,                  max_norm_grad = 17.218727111816406
round 91: local lr = 0.006205261219292879, norm_avg_grad = 0.8576788306236267, avg_norm_grad = 10.446020126342773,                  max_norm_grad = 16.815950393676758
round 92: local lr = 0.006101190112531185, norm_avg_grad = 0.8458561301231384, avg_norm_grad = 10.477753639221191,                  max_norm_grad = 16.7935791015625
round 93: local lr = 0.006524084135890007, norm_avg_grad = 0.9086697697639465, avg_norm_grad = 10.526226997375488,                  max_norm_grad = 16.797956466674805
round 94: local lr = 0.00652286596596241, norm_avg_grad = 0.9023545384407043, avg_norm_grad = 10.455022811889648,                  max_norm_grad = 16.832059860229492

>>> Round:   95 / Acc: 84.199% / Loss: 0.5165 /Time: 5.04s
======================================================================================================

= Test = round: 95 / acc: 85.220% / loss: 0.4864 / Time: 0.88s
======================================================================================================

round 95: local lr = 0.007639995310455561, norm_avg_grad = 1.0519134998321533, avg_norm_grad = 10.405744552612305,                  max_norm_grad = 17.05467414855957
round 96: local lr = 0.006885381415486336, norm_avg_grad = 0.9242193698883057, avg_norm_grad = 10.144561767578125,                  max_norm_grad = 16.351802825927734
round 97: local lr = 0.00783015787601471, norm_avg_grad = 1.0498007535934448, avg_norm_grad = 10.13263988494873,                  max_norm_grad = 16.18678855895996
round 98: local lr = 0.00804048590362072, norm_avg_grad = 1.0569963455200195, avg_norm_grad = 9.93521785736084,                  max_norm_grad = 16.139690399169922
round 99: local lr = 0.0074919736944139, norm_avg_grad = 0.9650499224662781, avg_norm_grad = 9.735085487365723,                  max_norm_grad = 15.683276176452637

>>> Round:  100 / Acc: 84.725% / Loss: 0.5069 /Time: 4.83s
======================================================================================================

= Test = round: 100 / acc: 85.790% / loss: 0.4755 / Time: 1.05s
======================================================================================================

round 100: local lr = 0.0066272905096411705, norm_avg_grad = 0.8526157140731812, avg_norm_grad = 9.72307300567627,                  max_norm_grad = 15.495628356933594
round 101: local lr = 0.005561338737607002, norm_avg_grad = 0.7189929485321045, avg_norm_grad = 9.770831108093262,                  max_norm_grad = 15.191428184509277
round 102: local lr = 0.0057157850824296474, norm_avg_grad = 0.7480566501617432, avg_norm_grad = 9.891105651855469,                  max_norm_grad = 15.544523239135742
round 103: local lr = 0.005126442294567823, norm_avg_grad = 0.6746546030044556, avg_norm_grad = 9.946072578430176,                  max_norm_grad = 15.445304870605469
round 104: local lr = 0.00547305541113019, norm_avg_grad = 0.7265547513961792, avg_norm_grad = 10.032858848571777,                  max_norm_grad = 15.737273216247559

>>> Round:  105 / Acc: 85.037% / Loss: 0.4914 /Time: 4.76s
======================================================================================================

= Test = round: 105 / acc: 86.150% / loss: 0.4617 / Time: 0.88s
======================================================================================================

round 105: local lr = 0.0070546530187129974, norm_avg_grad = 0.943418025970459, avg_norm_grad = 10.10682487487793,                  max_norm_grad = 16.308130264282227
round 106: local lr = 0.007132839411497116, norm_avg_grad = 0.9372556209564209, avg_norm_grad = 9.930745124816895,                  max_norm_grad = 16.050514221191406
round 107: local lr = 0.006561407819390297, norm_avg_grad = 0.8522530794143677, avg_norm_grad = 9.816524505615234,                  max_norm_grad = 15.760833740234375
round 108: local lr = 0.006593283265829086, norm_avg_grad = 0.8549415469169617, avg_norm_grad = 9.799882888793945,                  max_norm_grad = 15.74951457977295
round 109: local lr = 0.006397413555532694, norm_avg_grad = 0.8280501365661621, avg_norm_grad = 9.782241821289062,                  max_norm_grad = 15.72358226776123

>>> Round:  110 / Acc: 85.546% / Loss: 0.4800 /Time: 4.47s
======================================================================================================

= Test = round: 110 / acc: 86.670% / loss: 0.4496 / Time: 0.94s
======================================================================================================

round 110: local lr = 0.005354262422770262, norm_avg_grad = 0.6931694149971008, avg_norm_grad = 9.78421401977539,                  max_norm_grad = 15.355961799621582
round 111: local lr = 0.005502045154571533, norm_avg_grad = 0.719438374042511, avg_norm_grad = 9.882246017456055,                  max_norm_grad = 15.60440731048584
round 112: local lr = 0.005685798358172178, norm_avg_grad = 0.7460972666740417, avg_norm_grad = 9.91722583770752,                  max_norm_grad = 15.72993278503418
round 113: local lr = 0.0056967176496982574, norm_avg_grad = 0.7488070726394653, avg_norm_grad = 9.93416690826416,                  max_norm_grad = 15.790285110473633
round 114: local lr = 0.0056516616605222225, norm_avg_grad = 0.7434675693511963, avg_norm_grad = 9.941962242126465,                  max_norm_grad = 15.753151893615723

>>> Round:  115 / Acc: 85.806% / Loss: 0.4687 /Time: 4.64s
======================================================================================================

= Test = round: 115 / acc: 86.950% / loss: 0.4385 / Time: 0.87s
======================================================================================================

round 115: local lr = 0.005699521861970425, norm_avg_grad = 0.7515236735343933, avg_norm_grad = 9.965301513671875,                  max_norm_grad = 15.749957084655762
round 116: local lr = 0.0050106714479625225, norm_avg_grad = 0.6591196060180664, avg_norm_grad = 9.941559791564941,                  max_norm_grad = 15.406144142150879
round 117: local lr = 0.004670309834182262, norm_avg_grad = 0.6176818013191223, avg_norm_grad = 9.995518684387207,                  max_norm_grad = 15.312115669250488
round 118: local lr = 0.004970247857272625, norm_avg_grad = 0.661941409111023, avg_norm_grad = 10.065322875976562,                  max_norm_grad = 15.4175443649292
round 119: local lr = 0.006062378641217947, norm_avg_grad = 0.8108248114585876, avg_norm_grad = 10.108115196228027,                  max_norm_grad = 15.708769798278809

>>> Round:  120 / Acc: 86.068% / Loss: 0.4594 /Time: 4.50s
======================================================================================================

= Test = round: 120 / acc: 87.310% / loss: 0.4290 / Time: 0.88s
======================================================================================================

round 120: local lr = 0.0054779332131147385, norm_avg_grad = 0.7258761525154114, avg_norm_grad = 10.01456356048584,                  max_norm_grad = 15.568175315856934
round 121: local lr = 0.0056060729548335075, norm_avg_grad = 0.7454286813735962, avg_norm_grad = 10.049248695373535,                  max_norm_grad = 15.535109519958496
round 122: local lr = 0.005100297275930643, norm_avg_grad = 0.6766852140426636, avg_norm_grad = 10.02714729309082,                  max_norm_grad = 15.37271785736084
round 123: local lr = 0.005723415408283472, norm_avg_grad = 0.7633494138717651, avg_norm_grad = 10.079855918884277,                  max_norm_grad = 15.726585388183594
round 124: local lr = 0.005410106852650642, norm_avg_grad = 0.717539370059967, avg_norm_grad = 10.02365493774414,                  max_norm_grad = 15.68343734741211

>>> Round:  125 / Acc: 86.269% / Loss: 0.4510 /Time: 4.51s
======================================================================================================

= Test = round: 125 / acc: 87.400% / loss: 0.4210 / Time: 0.89s
======================================================================================================

round 125: local lr = 0.005853596609085798, norm_avg_grad = 0.7767617106437683, avg_norm_grad = 10.028852462768555,                  max_norm_grad = 15.80770206451416
round 126: local lr = 0.006812382489442825, norm_avg_grad = 0.8986236453056335, avg_norm_grad = 9.969307899475098,                  max_norm_grad = 15.978307723999023
round 127: local lr = 0.00742821441963315, norm_avg_grad = 0.959196150302887, avg_norm_grad = 9.759087562561035,                  max_norm_grad = 15.903170585632324
round 128: local lr = 0.008394422940909863, norm_avg_grad = 1.061910629272461, avg_norm_grad = 9.56056022644043,                  max_norm_grad = 15.779932975769043
round 129: local lr = 0.0060224574990570545, norm_avg_grad = 0.7350056171417236, avg_norm_grad = 9.22365665435791,                  max_norm_grad = 14.358798027038574

>>> Round:  130 / Acc: 86.661% / Loss: 0.4469 /Time: 4.73s
======================================================================================================

= Test = round: 130 / acc: 87.810% / loss: 0.4171 / Time: 0.90s
======================================================================================================

round 130: local lr = 0.004799568559974432, norm_avg_grad = 0.5889332890510559, avg_norm_grad = 9.273637771606445,                  max_norm_grad = 14.085594177246094
round 131: local lr = 0.004616051446646452, norm_avg_grad = 0.5724305510520935, avg_norm_grad = 9.37213134765625,                  max_norm_grad = 14.124944686889648
round 132: local lr = 0.004900023341178894, norm_avg_grad = 0.6135980486869812, avg_norm_grad = 9.463940620422363,                  max_norm_grad = 14.348395347595215
round 133: local lr = 0.004371748771518469, norm_avg_grad = 0.5512076020240784, avg_norm_grad = 9.528975486755371,                  max_norm_grad = 14.204549789428711
round 134: local lr = 0.0054244291968643665, norm_avg_grad = 0.6891257166862488, avg_norm_grad = 9.601313591003418,                  max_norm_grad = 14.612789154052734

>>> Round:  135 / Acc: 86.946% / Loss: 0.4363 /Time: 4.49s
======================================================================================================

= Test = round: 135 / acc: 88.040% / loss: 0.4067 / Time: 0.83s
======================================================================================================

round 135: local lr = 0.0051969364285469055, norm_avg_grad = 0.6622658967971802, avg_norm_grad = 9.630995750427246,                  max_norm_grad = 14.54417896270752
round 136: local lr = 0.004872526042163372, norm_avg_grad = 0.6230239868164062, avg_norm_grad = 9.663552284240723,                  max_norm_grad = 14.719353675842285
round 137: local lr = 0.004330276977270842, norm_avg_grad = 0.553729236125946, avg_norm_grad = 9.664246559143066,                  max_norm_grad = 14.714500427246094
round 138: local lr = 0.004891702439635992, norm_avg_grad = 0.6288456320762634, avg_norm_grad = 9.71561336517334,                  max_norm_grad = 14.910676002502441
round 139: local lr = 0.005731869023293257, norm_avg_grad = 0.7400128841400146, avg_norm_grad = 9.757290840148926,                  max_norm_grad = 15.285285949707031

>>> Round:  140 / Acc: 87.022% / Loss: 0.4293 /Time: 4.18s
======================================================================================================

= Test = round: 140 / acc: 88.070% / loss: 0.4000 / Time: 0.80s
======================================================================================================

round 140: local lr = 0.006283748894929886, norm_avg_grad = 0.8089966177940369, avg_norm_grad = 9.73002815246582,                  max_norm_grad = 15.400887489318848
round 141: local lr = 0.007019211072474718, norm_avg_grad = 0.8998878002166748, avg_norm_grad = 9.689163208007812,                  max_norm_grad = 15.181770324707031
round 142: local lr = 0.006549331359565258, norm_avg_grad = 0.8213663697242737, avg_norm_grad = 9.478206634521484,                  max_norm_grad = 14.536467552185059
round 143: local lr = 0.007153417449444532, norm_avg_grad = 0.889785885810852, avg_norm_grad = 9.400655746459961,                  max_norm_grad = 14.667010307312012
round 144: local lr = 0.006186364684253931, norm_avg_grad = 0.7517858147621155, avg_norm_grad = 9.184273719787598,                  max_norm_grad = 14.309349060058594

>>> Round:  145 / Acc: 87.212% / Loss: 0.4249 /Time: 4.39s
======================================================================================================

= Test = round: 145 / acc: 88.310% / loss: 0.3955 / Time: 0.88s
======================================================================================================

round 145: local lr = 0.0061735790222883224, norm_avg_grad = 0.7509774565696716, avg_norm_grad = 9.193399429321289,                  max_norm_grad = 14.30996322631836
round 146: local lr = 0.005420920439064503, norm_avg_grad = 0.6587209105491638, avg_norm_grad = 9.183635711669922,                  max_norm_grad = 13.987793922424316
round 147: local lr = 0.005607847589999437, norm_avg_grad = 0.6848495006561279, avg_norm_grad = 9.22964859008789,                  max_norm_grad = 14.211688995361328
round 148: local lr = 0.006008921656757593, norm_avg_grad = 0.7367883920669556, avg_norm_grad = 9.26685619354248,                  max_norm_grad = 14.461029052734375
round 149: local lr = 0.006489436142146587, norm_avg_grad = 0.7940022349357605, avg_norm_grad = 9.247002601623535,                  max_norm_grad = 14.68616008758545

>>> Round:  150 / Acc: 87.426% / Loss: 0.4177 /Time: 4.38s
======================================================================================================

= Test = round: 150 / acc: 88.340% / loss: 0.3888 / Time: 0.89s
======================================================================================================

round 150: local lr = 0.006175130605697632, norm_avg_grad = 0.7482286691665649, avg_norm_grad = 9.15744686126709,                  max_norm_grad = 14.478328704833984
round 151: local lr = 0.0067911213263869286, norm_avg_grad = 0.8205035924911499, avg_norm_grad = 9.131144523620605,                  max_norm_grad = 14.547938346862793
round 152: local lr = 0.005616327747702599, norm_avg_grad = 0.6771618127822876, avg_norm_grad = 9.112262725830078,                  max_norm_grad = 14.13789176940918
round 153: local lr = 0.005532869137823582, norm_avg_grad = 0.6713217496871948, avg_norm_grad = 9.169940948486328,                  max_norm_grad = 14.288156509399414
round 154: local lr = 0.00612199492752552, norm_avg_grad = 0.746312141418457, avg_norm_grad = 9.213269233703613,                  max_norm_grad = 14.554801940917969

>>> Round:  155 / Acc: 87.672% / Loss: 0.4099 /Time: 4.38s
======================================================================================================

= Test = round: 155 / acc: 88.640% / loss: 0.3812 / Time: 0.85s
======================================================================================================

round 155: local lr = 0.006030314136296511, norm_avg_grad = 0.7310943603515625, avg_norm_grad = 9.162620544433594,                  max_norm_grad = 14.293529510498047
round 156: local lr = 0.0061496892012655735, norm_avg_grad = 0.7458059191703796, avg_norm_grad = 9.165556907653809,                  max_norm_grad = 14.36330509185791
round 157: local lr = 0.005886304657906294, norm_avg_grad = 0.7114516496658325, avg_norm_grad = 9.1345853805542,                  max_norm_grad = 14.258174896240234
round 158: local lr = 0.0048476760275661945, norm_avg_grad = 0.5843740105628967, avg_norm_grad = 9.110527992248535,                  max_norm_grad = 13.846200942993164
round 159: local lr = 0.0038968513254076242, norm_avg_grad = 0.47208476066589355, avg_norm_grad = 9.155716896057129,                  max_norm_grad = 13.547426223754883

>>> Round:  160 / Acc: 87.917% / Loss: 0.4023 /Time: 4.73s
======================================================================================================

= Test = round: 160 / acc: 88.810% / loss: 0.3734 / Time: 0.81s
======================================================================================================

round 160: local lr = 0.004815828055143356, norm_avg_grad = 0.589016318321228, avg_norm_grad = 9.243630409240723,                  max_norm_grad = 13.901579856872559
round 161: local lr = 0.004871206358075142, norm_avg_grad = 0.5968528985977173, avg_norm_grad = 9.260128021240234,                  max_norm_grad = 14.047922134399414
round 162: local lr = 0.004460226744413376, norm_avg_grad = 0.5472166538238525, avg_norm_grad = 9.272323608398438,                  max_norm_grad = 13.898744583129883
round 163: local lr = 0.004902498330920935, norm_avg_grad = 0.6040282249450684, avg_norm_grad = 9.311635971069336,                  max_norm_grad = 14.212492942810059
round 164: local lr = 0.006004526279866695, norm_avg_grad = 0.7428666353225708, avg_norm_grad = 9.350144386291504,                  max_norm_grad = 14.606008529663086

>>> Round:  165 / Acc: 87.996% / Loss: 0.3970 /Time: 4.31s
======================================================================================================

= Test = round: 165 / acc: 88.830% / loss: 0.3689 / Time: 0.80s
======================================================================================================

round 165: local lr = 0.006026189308613539, norm_avg_grad = 0.7400597333908081, avg_norm_grad = 9.281330108642578,                  max_norm_grad = 14.518956184387207
round 166: local lr = 0.005502527579665184, norm_avg_grad = 0.6711655259132385, avg_norm_grad = 9.218358993530273,                  max_norm_grad = 14.000534057617188
round 167: local lr = 0.005375092849135399, norm_avg_grad = 0.6554237008094788, avg_norm_grad = 9.21557331085205,                  max_norm_grad = 14.143409729003906
round 168: local lr = 0.005270763300359249, norm_avg_grad = 0.6409872174263, avg_norm_grad = 9.190984725952148,                  max_norm_grad = 14.111473083496094
round 169: local lr = 0.004664630629122257, norm_avg_grad = 0.5660426616668701, avg_norm_grad = 9.171030044555664,                  max_norm_grad = 13.855124473571777

>>> Round:  170 / Acc: 88.286% / Loss: 0.3909 /Time: 4.41s
======================================================================================================

= Test = round: 170 / acc: 89.070% / loss: 0.3625 / Time: 0.79s
======================================================================================================

round 170: local lr = 0.005031230393797159, norm_avg_grad = 0.6118716597557068, avg_norm_grad = 9.191203117370605,                  max_norm_grad = 14.138965606689453
round 171: local lr = 0.005186548922210932, norm_avg_grad = 0.6334120035171509, avg_norm_grad = 9.229836463928223,                  max_norm_grad = 14.177644729614258
round 172: local lr = 0.005122306756675243, norm_avg_grad = 0.6243899464607239, avg_norm_grad = 9.212478637695312,                  max_norm_grad = 14.15501594543457
round 173: local lr = 0.005670453887432814, norm_avg_grad = 0.6911355257034302, avg_norm_grad = 9.211525917053223,                  max_norm_grad = 14.359201431274414
round 174: local lr = 0.00502321682870388, norm_avg_grad = 0.6091016530990601, avg_norm_grad = 9.164189338684082,                  max_norm_grad = 14.112394332885742

>>> Round:  175 / Acc: 88.426% / Loss: 0.3862 /Time: 4.24s
======================================================================================================

= Test = round: 175 / acc: 89.370% / loss: 0.3578 / Time: 0.80s
======================================================================================================

round 175: local lr = 0.005656428635120392, norm_avg_grad = 0.6860527992248535, avg_norm_grad = 9.166455268859863,                  max_norm_grad = 14.309747695922852
round 176: local lr = 0.005687199532985687, norm_avg_grad = 0.6901978850364685, avg_norm_grad = 9.171943664550781,                  max_norm_grad = 14.187642097473145
round 177: local lr = 0.006196684204041958, norm_avg_grad = 0.750356912612915, avg_norm_grad = 9.151552200317383,                  max_norm_grad = 14.268027305603027
round 178: local lr = 0.005905156023800373, norm_avg_grad = 0.705920934677124, avg_norm_grad = 9.03464126586914,                  max_norm_grad = 13.957135200500488
round 179: local lr = 0.005501091945916414, norm_avg_grad = 0.651936948299408, avg_norm_grad = 8.956594467163086,                  max_norm_grad = 13.750234603881836

>>> Round:  180 / Acc: 88.531% / Loss: 0.3817 /Time: 4.31s
======================================================================================================

= Test = round: 180 / acc: 89.500% / loss: 0.3535 / Time: 0.79s
======================================================================================================

round 180: local lr = 0.005431149620562792, norm_avg_grad = 0.6428307294845581, avg_norm_grad = 8.945220947265625,                  max_norm_grad = 13.75570297241211
round 181: local lr = 0.005711314734071493, norm_avg_grad = 0.6758473515510559, avg_norm_grad = 8.943319320678711,                  max_norm_grad = 13.813199996948242
round 182: local lr = 0.004171174950897694, norm_avg_grad = 0.49360284209251404, avg_norm_grad = 8.94345760345459,                  max_norm_grad = 13.11929702758789
round 183: local lr = 0.004672805778682232, norm_avg_grad = 0.5560182332992554, avg_norm_grad = 8.992853164672852,                  max_norm_grad = 13.595118522644043
round 184: local lr = 0.004720439203083515, norm_avg_grad = 0.5653764009475708, avg_norm_grad = 9.051936149597168,                  max_norm_grad = 13.432771682739258

>>> Round:  185 / Acc: 88.703% / Loss: 0.3758 /Time: 4.32s
======================================================================================================

= Test = round: 185 / acc: 89.620% / loss: 0.3473 / Time: 0.85s
======================================================================================================

round 185: local lr = 0.004574023652821779, norm_avg_grad = 0.5488950610160828, avg_norm_grad = 9.06937026977539,                  max_norm_grad = 13.255943298339844
round 186: local lr = 0.004251556470990181, norm_avg_grad = 0.5110824108123779, avg_norm_grad = 9.085089683532715,                  max_norm_grad = 13.292265892028809
round 187: local lr = 0.0047497437335550785, norm_avg_grad = 0.5737988352775574, avg_norm_grad = 9.130104064941406,                  max_norm_grad = 13.479964256286621
round 188: local lr = 0.005147760268300772, norm_avg_grad = 0.6221610307693481, avg_norm_grad = 9.134203910827637,                  max_norm_grad = 13.948528289794922
round 189: local lr = 0.005491925869137049, norm_avg_grad = 0.663003146648407, avg_norm_grad = 9.123828887939453,                  max_norm_grad = 14.080241203308105

>>> Round:  190 / Acc: 88.758% / Loss: 0.3717 /Time: 4.40s
======================================================================================================

= Test = round: 190 / acc: 89.770% / loss: 0.3436 / Time: 0.81s
======================================================================================================

round 190: local lr = 0.005552316550165415, norm_avg_grad = 0.6691588163375854, avg_norm_grad = 9.108381271362305,                  max_norm_grad = 14.089088439941406
round 191: local lr = 0.004937529098242521, norm_avg_grad = 0.5915955901145935, avg_norm_grad = 9.05527114868164,                  max_norm_grad = 13.800033569335938
round 192: local lr = 0.004679437261074781, norm_avg_grad = 0.5618296265602112, avg_norm_grad = 9.073967933654785,                  max_norm_grad = 13.703989028930664
round 193: local lr = 0.00437703263014555, norm_avg_grad = 0.5273637175559998, avg_norm_grad = 9.105770111083984,                  max_norm_grad = 13.387967109680176
round 194: local lr = 0.004536643158644438, norm_avg_grad = 0.5491471886634827, avg_norm_grad = 9.148299217224121,                  max_norm_grad = 13.604708671569824

>>> Round:  195 / Acc: 88.895% / Loss: 0.3668 /Time: 4.24s
======================================================================================================

= Test = round: 195 / acc: 89.900% / loss: 0.3390 / Time: 0.83s
======================================================================================================

round 195: local lr = 0.005053984001278877, norm_avg_grad = 0.6130613088607788, avg_norm_grad = 9.16761302947998,                  max_norm_grad = 13.634181022644043
round 196: local lr = 0.006283415947109461, norm_avg_grad = 0.758415937423706, avg_norm_grad = 9.122163772583008,                  max_norm_grad = 14.057000160217285
round 197: local lr = 0.006505497731268406, norm_avg_grad = 0.774897038936615, avg_norm_grad = 9.00222110748291,                  max_norm_grad = 13.527358055114746
round 198: local lr = 0.006443679798394442, norm_avg_grad = 0.7533682584762573, avg_norm_grad = 8.836078643798828,                  max_norm_grad = 13.46354866027832
round 199: local lr = 0.007531710900366306, norm_avg_grad = 0.8751980662345886, avg_norm_grad = 8.782111167907715,                  max_norm_grad = 13.682755470275879

>>> Round:  200 / Acc: 88.993% / Loss: 0.3669 /Time: 4.87s
======================================================================================================

= Test = round: 200 / acc: 89.860% / loss: 0.3395 / Time: 1.13s
======================================================================================================

>>> Training model_ft
Epoch: 001, Train_loss: 1.3162, Train_acc: 0.5859, Test_loss: 1.2923, Test_acc: 0.5936
Epoch: 006, Train_loss: 1.0121, Train_acc: 0.6799, Test_loss: 1.0031, Test_acc: 0.6839
Epoch: 011, Train_loss: 0.9331, Train_acc: 0.7055, Test_loss: 0.9373, Test_acc: 0.7061
Epoch: 016, Train_loss: 0.9021, Train_acc: 0.7143, Test_loss: 0.9124, Test_acc: 0.7119
Epoch: 021, Train_loss: 0.8677, Train_acc: 0.7225, Test_loss: 0.8936, Test_acc: 0.7180
Epoch: 026, Train_loss: 0.8400, Train_acc: 0.7320, Test_loss: 0.8730, Test_acc: 0.7255
Epoch: 031, Train_loss: 0.8242, Train_acc: 0.7350, Test_loss: 0.8613, Test_acc: 0.7274
Epoch: 036, Train_loss: 0.8320, Train_acc: 0.7299, Test_loss: 0.8740, Test_acc: 0.7226
Epoch: 041, Train_loss: 0.7907, Train_acc: 0.7457, Test_loss: 0.8370, Test_acc: 0.7354
Epoch: 046, Train_loss: 0.7804, Train_acc: 0.7505, Test_loss: 0.8316, Test_acc: 0.7421
Epoch: 051, Train_loss: 0.7756, Train_acc: 0.7512, Test_loss: 0.8287, Test_acc: 0.7388
Epoch: 056, Train_loss: 0.7636, Train_acc: 0.7566, Test_loss: 0.8270, Test_acc: 0.7439
Epoch: 061, Train_loss: 0.7790, Train_acc: 0.7499, Test_loss: 0.8446, Test_acc: 0.7326
Epoch: 066, Train_loss: 0.7571, Train_acc: 0.7565, Test_loss: 0.8309, Test_acc: 0.7384
Epoch: 071, Train_loss: 0.7460, Train_acc: 0.7598, Test_loss: 0.8156, Test_acc: 0.7434
Epoch: 076, Train_loss: 0.7463, Train_acc: 0.7556, Test_loss: 0.8217, Test_acc: 0.7410
Epoch: 081, Train_loss: 0.7341, Train_acc: 0.7612, Test_loss: 0.8122, Test_acc: 0.7434
Epoch: 086, Train_loss: 0.7299, Train_acc: 0.7650, Test_loss: 0.8160, Test_acc: 0.7439
Epoch: 091, Train_loss: 0.7285, Train_acc: 0.7650, Test_loss: 0.8229, Test_acc: 0.7418
Epoch: 096, Train_loss: 0.7195, Train_acc: 0.7675, Test_loss: 0.8168, Test_acc: 0.7391
Epoch: 101, Train_loss: 0.7247, Train_acc: 0.7646, Test_loss: 0.8150, Test_acc: 0.7414
Epoch: 106, Train_loss: 0.7346, Train_acc: 0.7609, Test_loss: 0.8382, Test_acc: 0.7366
Fine-tuning early stopped. Model saved at ./models/ft_checkpoints/20230928000640_model_ft.pt.
Model saved at ./models/ft_checkpoints/20230928000640_model_ft.pt.
>>> Fine-tuning done!
>>> Evaluating model_source_only
model_ft: [0.7088040335982803, 0.7711225233470619, 0.8016418802805734, 0.7460282190867681]
model_source_only: [2.8880964906148465, 0.4003830443551804, 2.9412470653764062, 0.39862237529163425]
fl_test_acc_mean 0.8974
model_source_only_test_acc_mean 0.39862237529163425
model_ft_test_acc_mean 0.7460282190867681
