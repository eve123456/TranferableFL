nohup: ignoring input
working!
check why cannot sync
Using device: cuda:0
>>> Arguments:
	             algo : fedavgtl
	            alpha : 13.2316427
	       batch_size : 64
	clients_per_round : 100
	             clip : False
	          dataset : mnist_all_data_1_equal_niid
	           device : cuda:0
	              dis : 
	   early_stopping : 10
	       eval_every : 5
	    ft_batch_size : 128
	       ft_dataset : mnist-m
	        ft_epochs : 200
	            ft_lr : 0.001
	            ft_wd : 0.0001
	              gpu : True
	      input_shape : (1, 28, 28)
	           last_k : 1
	               lr : 0.01
	            model : lenet
	           n_init : 1
	        noaverage : False
	             noft : False
	          noprint : False
	        num_class : 10
	        num_epoch : 1
	        num_round : 200
	           opt_lr : True
	            reg_J : False
	       reg_J_coef : 0.0
	   reg_J_ind_coef : 0.001
	  reg_J_norm_coef : 0.0
	          reg_max : True
	           repeat : 1
	     repeat_epoch : 10
	             seed : 0
	               wd : 0.0
>>> Read data from:
     ./data/mnist/data/all_data_1.pkl
>>> The estimate of constant alpha is 13.2316427.
>>> Read data from:
     ./data/mnist/data/train/all_data_1_equal_niid.pkl
     ./data/mnist/data/test/all_data_1_equal_niid.pkl

************************************************************************************************************************

uid: 20230928000440
FL pretrained model will be saved at ./models/lenet_mnist_20230928000440.pt
>>> Use gpu on device cuda:0
>>> Model statistic per layer
LeNet_MNIST(
  286.12 KMac, 100.000% MACs, 
  (conv1): Conv2d(89.856 KMac, 31.405% MACs, 1, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(154.624 KMac, 54.042% MACs, 6, 16, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(30.72 KMac, 10.737% MACs, in_features=256, out_features=120, bias=True)
  (fc2): Linear(10.08 KMac, 3.523% MACs, in_features=120, out_features=84, bias=True)
  (fc3): Linear(840.0 Mac, 0.294% MACs, in_features=84, out_features=10, bias=True)
)
>>> Activate a worker for training
>>> Initialize 100 clients in total
>>> Weigh updates by simple average
>>> Select 100 clients per round 


>>> Round:    0 / Acc: 10.482% / Loss: 2.3042 /Time: 5.73s
======================================================================================================

= Test = round: 0 / acc: 10.230% / loss: 2.3061 / Time: 1.19s
======================================================================================================

round 0: local lr = 0.01
round 1: local lr = 0.0105685880407691, norm_avg_grad = 0.15744052827358246, avg_norm_grad = 1.1258636713027954,                  max_norm_grad = 1.3066877126693726
round 2: local lr = 0.010286720469594002, norm_avg_grad = 0.16605481505393982, avg_norm_grad = 1.22000253200531,                  max_norm_grad = 1.4339656829833984
round 3: local lr = 0.010003817267715931, norm_avg_grad = 0.17833168804645538, avg_norm_grad = 1.3472524881362915,                  max_norm_grad = 1.6082044839859009
round 4: local lr = 0.009649322368204594, norm_avg_grad = 0.19454257190227509, avg_norm_grad = 1.5237159729003906,                  max_norm_grad = 1.8497319221496582

>>> Round:    5 / Acc: 17.380% / Loss: 2.2864 /Time: 6.36s
======================================================================================================

= Test = round: 5 / acc: 17.370% / loss: 2.2875 / Time: 1.05s
======================================================================================================

round 5: local lr = 0.009182799607515335, norm_avg_grad = 0.2145383059978485, avg_norm_grad = 1.7656960487365723,                  max_norm_grad = 2.179922342300415
round 6: local lr = 0.00860773865133524, norm_avg_grad = 0.23972055315971375, avg_norm_grad = 2.1047592163085938,                  max_norm_grad = 2.6104888916015625
round 7: local lr = 0.008059226907789707, norm_avg_grad = 0.27568650245666504, avg_norm_grad = 2.585284471511841,                  max_norm_grad = 3.182511568069458
round 8: local lr = 0.007634127978235483, norm_avg_grad = 0.33097729086875916, avg_norm_grad = 3.276611566543579,                  max_norm_grad = 3.9708051681518555
round 9: local lr = 0.007447635289281607, norm_avg_grad = 0.4242854118347168, avg_norm_grad = 4.305522918701172,                  max_norm_grad = 5.106257915496826

>>> Round:   10 / Acc: 23.424% / Loss: 2.2391 /Time: 4.67s
======================================================================================================

= Test = round: 10 / acc: 24.600% / loss: 2.2373 / Time: 0.83s
======================================================================================================

round 10: local lr = 0.007570609916001558, norm_avg_grad = 0.5912384390830994, avg_norm_grad = 5.902255535125732,                  max_norm_grad = 6.9053778648376465
round 11: local lr = 0.007600618060678244, norm_avg_grad = 0.8262268304824829, avg_norm_grad = 8.21554946899414,                  max_norm_grad = 9.666572570800781
round 12: local lr = 0.007801935076713562, norm_avg_grad = 1.1156566143035889, avg_norm_grad = 10.807230949401855,                  max_norm_grad = 12.726861953735352
round 13: local lr = 0.009358624927699566, norm_avg_grad = 1.5640678405761719, avg_norm_grad = 12.630767822265625,                  max_norm_grad = 15.101239204406738
round 14: local lr = 0.010095200501382351, norm_avg_grad = 1.6637130975723267, avg_norm_grad = 12.455171585083008,                  max_norm_grad = 15.018475532531738

>>> Round:   15 / Acc: 38.963% / Loss: 2.1161 /Time: 4.43s
======================================================================================================

= Test = round: 15 / acc: 41.310% / loss: 2.1046 / Time: 0.84s
======================================================================================================

round 15: local lr = 0.010467282496392727, norm_avg_grad = 1.6859644651412964, avg_norm_grad = 12.17308521270752,                  max_norm_grad = 14.681985855102539
round 16: local lr = 0.010252630338072777, norm_avg_grad = 1.6267224550247192, avg_norm_grad = 11.99124813079834,                  max_norm_grad = 14.40051555633545
round 17: local lr = 0.010371698066592216, norm_avg_grad = 1.6314418315887451, avg_norm_grad = 11.88797664642334,                  max_norm_grad = 14.288925170898438
round 18: local lr = 0.01040798332542181, norm_avg_grad = 1.6315937042236328, avg_norm_grad = 11.847634315490723,                  max_norm_grad = 14.22856330871582
round 19: local lr = 0.010414942167699337, norm_avg_grad = 1.6404832601547241, avg_norm_grad = 11.90422534942627,                  max_norm_grad = 14.372982025146484

>>> Round:   20 / Acc: 52.358% / Loss: 1.8951 /Time: 4.42s
======================================================================================================

= Test = round: 20 / acc: 54.680% / loss: 1.8736 / Time: 0.86s
======================================================================================================

round 20: local lr = 0.010796261951327324, norm_avg_grad = 1.7064751386642456, avg_norm_grad = 11.945731163024902,                  max_norm_grad = 14.390602111816406
round 21: local lr = 0.01047279592603445, norm_avg_grad = 1.6423568725585938, avg_norm_grad = 11.851984977722168,                  max_norm_grad = 14.163249969482422
round 22: local lr = 0.010703795589506626, norm_avg_grad = 1.7047638893127441, avg_norm_grad = 12.036845207214355,                  max_norm_grad = 14.49143123626709
round 23: local lr = 0.01085590198636055, norm_avg_grad = 1.6905597448349, avg_norm_grad = 11.769304275512695,                  max_norm_grad = 14.273971557617188
round 24: local lr = 0.011179771274328232, norm_avg_grad = 1.724906325340271, avg_norm_grad = 11.660544395446777,                  max_norm_grad = 14.291646957397461

>>> Round:   25 / Acc: 56.478% / Loss: 1.6271 /Time: 4.35s
======================================================================================================

= Test = round: 25 / acc: 59.030% / loss: 1.5916 / Time: 0.85s
======================================================================================================

round 25: local lr = 0.01090677548199892, norm_avg_grad = 1.676605463027954, avg_norm_grad = 11.617715835571289,                  max_norm_grad = 14.053122520446777
round 26: local lr = 0.011240742169320583, norm_avg_grad = 1.733443021774292, avg_norm_grad = 11.654691696166992,                  max_norm_grad = 14.06032943725586
round 27: local lr = 0.010965043678879738, norm_avg_grad = 1.670656442642212, avg_norm_grad = 11.514975547790527,                  max_norm_grad = 13.9151029586792
round 28: local lr = 0.010807218961417675, norm_avg_grad = 1.6517311334609985, avg_norm_grad = 11.550787925720215,                  max_norm_grad = 13.848189353942871
round 29: local lr = 0.010769762098789215, norm_avg_grad = 1.6481817960739136, avg_norm_grad = 11.566054344177246,                  max_norm_grad = 13.938535690307617

>>> Round:   30 / Acc: 61.664% / Loss: 1.3838 /Time: 4.44s
======================================================================================================

= Test = round: 30 / acc: 64.150% / loss: 1.3413 / Time: 0.84s
======================================================================================================

round 30: local lr = 0.011320790275931358, norm_avg_grad = 1.7283636331558228, avg_norm_grad = 11.538373947143555,                  max_norm_grad = 14.034906387329102
round 31: local lr = 0.011457077227532864, norm_avg_grad = 1.7068895101547241, avg_norm_grad = 11.259465217590332,                  max_norm_grad = 13.824353218078613
round 32: local lr = 0.011697709560394287, norm_avg_grad = 1.7143733501434326, avg_norm_grad = 11.076199531555176,                  max_norm_grad = 13.654461860656738
round 33: local lr = 0.011930038221180439, norm_avg_grad = 1.7505431175231934, avg_norm_grad = 11.08963394165039,                  max_norm_grad = 13.82911491394043
round 34: local lr = 0.012138934805989265, norm_avg_grad = 1.7257885932922363, avg_norm_grad = 10.744673728942871,                  max_norm_grad = 13.358047485351562

>>> Round:   35 / Acc: 66.884% / Loss: 1.1907 /Time: 4.55s
======================================================================================================

= Test = round: 35 / acc: 69.450% / loss: 1.1488 / Time: 0.89s
======================================================================================================

round 35: local lr = 0.01172575168311596, norm_avg_grad = 1.6605381965637207, avg_norm_grad = 10.702725410461426,                  max_norm_grad = 13.278097152709961
round 36: local lr = 0.011920593678951263, norm_avg_grad = 1.7030773162841797, avg_norm_grad = 10.797487258911133,                  max_norm_grad = 13.545275688171387
round 37: local lr = 0.012334655039012432, norm_avg_grad = 1.7381857633590698, avg_norm_grad = 10.650141716003418,                  max_norm_grad = 13.584120750427246
round 38: local lr = 0.01279541663825512, norm_avg_grad = 1.7870951890945435, avg_norm_grad = 10.555516242980957,                  max_norm_grad = 13.569421768188477
round 39: local lr = 0.013007172383368015, norm_avg_grad = 1.7856546640396118, avg_norm_grad = 10.375303268432617,                  max_norm_grad = 13.27520751953125

>>> Round:   40 / Acc: 69.225% / Loss: 1.0345 /Time: 5.58s
======================================================================================================

= Test = round: 40 / acc: 71.090% / loss: 0.9963 / Time: 0.99s
======================================================================================================

round 40: local lr = 0.014779828488826752, norm_avg_grad = 2.0129706859588623, avg_norm_grad = 10.293291091918945,                  max_norm_grad = 13.39006233215332
round 41: local lr = 0.01445704884827137, norm_avg_grad = 1.8496099710464478, avg_norm_grad = 9.66911506652832,                  max_norm_grad = 12.511144638061523
round 42: local lr = 0.013742941431701183, norm_avg_grad = 1.7493767738342285, avg_norm_grad = 9.620327949523926,                  max_norm_grad = 12.544710159301758
round 43: local lr = 0.013947163708508015, norm_avg_grad = 1.7788398265838623, avg_norm_grad = 9.639115333557129,                  max_norm_grad = 12.702510833740234
round 44: local lr = 0.013192709535360336, norm_avg_grad = 1.6748578548431396, avg_norm_grad = 9.594672203063965,                  max_norm_grad = 12.58211898803711

>>> Round:   45 / Acc: 74.103% / Loss: 0.8919 /Time: 7.15s
======================================================================================================

= Test = round: 45 / acc: 75.710% / loss: 0.8561 / Time: 1.29s
======================================================================================================

round 45: local lr = 0.013879491947591305, norm_avg_grad = 1.779435634613037, avg_norm_grad = 9.689356803894043,                  max_norm_grad = 12.774008750915527
round 46: local lr = 0.01440894603729248, norm_avg_grad = 1.7926695346832275, avg_norm_grad = 9.402735710144043,                  max_norm_grad = 12.445277214050293
round 47: local lr = 0.013597747310996056, norm_avg_grad = 1.6686692237854004, avg_norm_grad = 9.274478912353516,                  max_norm_grad = 12.321657180786133
round 48: local lr = 0.014016094617545605, norm_avg_grad = 1.7113157510757446, avg_norm_grad = 9.227612495422363,                  max_norm_grad = 12.349912643432617
round 49: local lr = 0.01454831287264824, norm_avg_grad = 1.7617299556732178, avg_norm_grad = 9.151934623718262,                  max_norm_grad = 12.326909065246582

>>> Round:   50 / Acc: 76.469% / Loss: 0.7980 /Time: 5.48s
======================================================================================================

= Test = round: 50 / acc: 78.470% / loss: 0.7625 / Time: 1.03s
======================================================================================================

round 50: local lr = 0.01420656032860279, norm_avg_grad = 1.6865791082382202, avg_norm_grad = 8.972304344177246,                  max_norm_grad = 12.347437858581543
round 51: local lr = 0.013643176294863224, norm_avg_grad = 1.5993053913116455, avg_norm_grad = 8.859355926513672,                  max_norm_grad = 12.269775390625
round 52: local lr = 0.013925375416874886, norm_avg_grad = 1.6107189655303955, avg_norm_grad = 8.741764068603516,                  max_norm_grad = 12.168376922607422
round 53: local lr = 0.013150127604603767, norm_avg_grad = 1.5122367143630981, avg_norm_grad = 8.69112491607666,                  max_norm_grad = 12.075886726379395
round 54: local lr = 0.013866040855646133, norm_avg_grad = 1.5754411220550537, avg_norm_grad = 8.58689022064209,                  max_norm_grad = 12.11097240447998

>>> Round:   55 / Acc: 78.622% / Loss: 0.7214 /Time: 5.60s
======================================================================================================

= Test = round: 55 / acc: 80.460% / loss: 0.6865 / Time: 1.10s
======================================================================================================

round 55: local lr = 0.013818073086440563, norm_avg_grad = 1.553869605064392, avg_norm_grad = 8.4987154006958,                  max_norm_grad = 12.08030891418457
round 56: local lr = 0.014718507416546345, norm_avg_grad = 1.6549595594406128, avg_norm_grad = 8.497864723205566,                  max_norm_grad = 12.397665977478027
round 57: local lr = 0.0160085279494524, norm_avg_grad = 1.7730085849761963, avg_norm_grad = 8.370388984680176,                  max_norm_grad = 12.263246536254883
round 58: local lr = 0.015938417986035347, norm_avg_grad = 1.656543493270874, avg_norm_grad = 7.854957103729248,                  max_norm_grad = 11.377679824829102
round 59: local lr = 0.014846619218587875, norm_avg_grad = 1.5360357761383057, avg_norm_grad = 7.819157600402832,                  max_norm_grad = 11.427799224853516

>>> Round:   60 / Acc: 80.266% / Loss: 0.6677 /Time: 5.38s
======================================================================================================

= Test = round: 60 / acc: 82.090% / loss: 0.6330 / Time: 1.01s
======================================================================================================

round 60: local lr = 0.01391048263758421, norm_avg_grad = 1.4440696239471436, avg_norm_grad = 7.845707893371582,                  max_norm_grad = 11.296436309814453
round 61: local lr = 0.01214308850467205, norm_avg_grad = 1.2691073417663574, avg_norm_grad = 7.898695945739746,                  max_norm_grad = 11.300724029541016
round 62: local lr = 0.013012593612074852, norm_avg_grad = 1.3779407739639282, avg_norm_grad = 8.00300121307373,                  max_norm_grad = 11.65257453918457
round 63: local lr = 0.014768370427191257, norm_avg_grad = 1.5627813339233398, avg_norm_grad = 7.997456073760986,                  max_norm_grad = 12.022382736206055
round 64: local lr = 0.015341424383223057, norm_avg_grad = 1.582497477531433, avg_norm_grad = 7.795851230621338,                  max_norm_grad = 11.74827766418457

>>> Round:   65 / Acc: 81.314% / Loss: 0.6221 /Time: 4.36s
======================================================================================================

= Test = round: 65 / acc: 82.990% / loss: 0.5874 / Time: 0.88s
======================================================================================================

round 65: local lr = 0.014887618832290173, norm_avg_grad = 1.490408182144165, avg_norm_grad = 7.56599760055542,                  max_norm_grad = 11.513999938964844
round 66: local lr = 0.014880213886499405, norm_avg_grad = 1.4816445112228394, avg_norm_grad = 7.525252342224121,                  max_norm_grad = 11.426556587219238
round 67: local lr = 0.015789998695254326, norm_avg_grad = 1.5521529912948608, avg_norm_grad = 7.429141521453857,                  max_norm_grad = 11.461044311523438
round 68: local lr = 0.01490672305226326, norm_avg_grad = 1.424544095993042, avg_norm_grad = 7.222373008728027,                  max_norm_grad = 11.022234916687012
round 69: local lr = 0.013605950400233269, norm_avg_grad = 1.2882885932922363, avg_norm_grad = 7.156002521514893,                  max_norm_grad = 10.9727783203125

>>> Round:   70 / Acc: 82.714% / Loss: 0.5774 /Time: 4.35s
======================================================================================================

= Test = round: 70 / acc: 84.410% / loss: 0.5434 / Time: 0.91s
======================================================================================================

round 70: local lr = 0.014315996319055557, norm_avg_grad = 1.379433035850525, avg_norm_grad = 7.282244682312012,                  max_norm_grad = 11.185540199279785
round 71: local lr = 0.01481375377625227, norm_avg_grad = 1.4173610210418701, avg_norm_grad = 7.231053352355957,                  max_norm_grad = 11.277179718017578
round 72: local lr = 0.014109455980360508, norm_avg_grad = 1.3492103815078735, avg_norm_grad = 7.226959705352783,                  max_norm_grad = 11.23530101776123
round 73: local lr = 0.013626006431877613, norm_avg_grad = 1.2719279527664185, avg_norm_grad = 7.054725646972656,                  max_norm_grad = 10.929350852966309
round 74: local lr = 0.013580339960753918, norm_avg_grad = 1.2806594371795654, avg_norm_grad = 7.127040863037109,                  max_norm_grad = 11.1800537109375

>>> Round:   75 / Acc: 83.886% / Loss: 0.5395 /Time: 4.99s
======================================================================================================

= Test = round: 75 / acc: 85.340% / loss: 0.5058 / Time: 0.86s
======================================================================================================

round 75: local lr = 0.01364794373512268, norm_avg_grad = 1.2868729829788208, avg_norm_grad = 7.126145362854004,                  max_norm_grad = 11.194928169250488
round 76: local lr = 0.013623041100800037, norm_avg_grad = 1.2818701267242432, avg_norm_grad = 7.111417293548584,                  max_norm_grad = 11.205219268798828
round 77: local lr = 0.01371986698359251, norm_avg_grad = 1.2755985260009766, avg_norm_grad = 7.026681900024414,                  max_norm_grad = 11.202350616455078
round 78: local lr = 0.013772147707641125, norm_avg_grad = 1.275500774383545, avg_norm_grad = 6.999471664428711,                  max_norm_grad = 11.045112609863281
round 79: local lr = 0.014212789945304394, norm_avg_grad = 1.3020213842391968, avg_norm_grad = 6.923488616943359,                  max_norm_grad = 10.748960494995117

>>> Round:   80 / Acc: 84.716% / Loss: 0.5143 /Time: 5.25s
======================================================================================================

= Test = round: 80 / acc: 86.100% / loss: 0.4803 / Time: 0.93s
======================================================================================================

round 80: local lr = 0.013612535782158375, norm_avg_grad = 1.2321773767471313, avg_norm_grad = 6.841012954711914,                  max_norm_grad = 10.620684623718262
round 81: local lr = 0.012778038159012794, norm_avg_grad = 1.1556649208068848, avg_norm_grad = 6.835242748260498,                  max_norm_grad = 10.704849243164062
round 82: local lr = 0.013037064112722874, norm_avg_grad = 1.1778008937835693, avg_norm_grad = 6.827760696411133,                  max_norm_grad = 10.870373725891113
round 83: local lr = 0.013760882429778576, norm_avg_grad = 1.2511154413223267, avg_norm_grad = 6.871274471282959,                  max_norm_grad = 11.050947189331055
round 84: local lr = 0.013286206871271133, norm_avg_grad = 1.19303560256958, avg_norm_grad = 6.786386489868164,                  max_norm_grad = 10.823290824890137

>>> Round:   85 / Acc: 85.397% / Loss: 0.4875 /Time: 4.99s
======================================================================================================

= Test = round: 85 / acc: 86.900% / loss: 0.4540 / Time: 0.87s
======================================================================================================

round 85: local lr = 0.013926707208156586, norm_avg_grad = 1.2528102397918701, avg_norm_grad = 6.798655986785889,                  max_norm_grad = 10.880858421325684
round 86: local lr = 0.015114287845790386, norm_avg_grad = 1.343037486076355, avg_norm_grad = 6.715628623962402,                  max_norm_grad = 11.03236198425293
round 87: local lr = 0.013677871786057949, norm_avg_grad = 1.1691714525222778, avg_norm_grad = 6.460198879241943,                  max_norm_grad = 10.475852966308594
round 88: local lr = 0.013280309736728668, norm_avg_grad = 1.131508708000183, avg_norm_grad = 6.4392595291137695,                  max_norm_grad = 10.446595191955566
round 89: local lr = 0.014242713339626789, norm_avg_grad = 1.2196227312088013, avg_norm_grad = 6.47170877456665,                  max_norm_grad = 10.591139793395996

>>> Round:   90 / Acc: 85.849% / Loss: 0.4752 /Time: 5.60s
======================================================================================================

= Test = round: 90 / acc: 87.390% / loss: 0.4413 / Time: 0.93s
======================================================================================================

round 90: local lr = 0.014910734258592129, norm_avg_grad = 1.2623742818832397, avg_norm_grad = 6.398458003997803,                  max_norm_grad = 10.365201950073242
round 91: local lr = 0.013925369828939438, norm_avg_grad = 1.16928231716156, avg_norm_grad = 6.345982551574707,                  max_norm_grad = 10.202142715454102
round 92: local lr = 0.01374876406043768, norm_avg_grad = 1.1524930000305176, avg_norm_grad = 6.335207462310791,                  max_norm_grad = 10.039090156555176
round 93: local lr = 0.012764498591423035, norm_avg_grad = 1.0751315355300903, avg_norm_grad = 6.365669250488281,                  max_norm_grad = 9.979843139648438
round 94: local lr = 0.012969858944416046, norm_avg_grad = 1.081751823425293, avg_norm_grad = 6.303454399108887,                  max_norm_grad = 9.971855163574219

>>> Round:   95 / Acc: 86.690% / Loss: 0.4493 /Time: 5.03s
======================================================================================================

= Test = round: 95 / acc: 87.990% / loss: 0.4168 / Time: 1.01s
======================================================================================================

round 95: local lr = 0.013290042988955975, norm_avg_grad = 1.1126919984817505, avg_norm_grad = 6.32753849029541,                  max_norm_grad = 10.10324764251709
round 96: local lr = 0.012461514212191105, norm_avg_grad = 1.0378488302230835, avg_norm_grad = 6.294329643249512,                  max_norm_grad = 9.92862319946289
round 97: local lr = 0.013253046199679375, norm_avg_grad = 1.1144269704818726, avg_norm_grad = 6.355096340179443,                  max_norm_grad = 10.10912036895752
round 98: local lr = 0.013089275918900967, norm_avg_grad = 1.0954017639160156, avg_norm_grad = 6.324759483337402,                  max_norm_grad = 10.185518264770508
round 99: local lr = 0.012612035498023033, norm_avg_grad = 1.0352704524993896, avg_norm_grad = 6.203758239746094,                  max_norm_grad = 9.9684419631958

>>> Round:  100 / Acc: 87.089% / Loss: 0.4319 /Time: 4.91s
======================================================================================================

= Test = round: 100 / acc: 88.410% / loss: 0.3988 / Time: 0.96s
======================================================================================================

round 100: local lr = 0.013503444381058216, norm_avg_grad = 1.1153411865234375, avg_norm_grad = 6.242368221282959,                  max_norm_grad = 10.301996231079102
round 101: local lr = 0.013764981180429459, norm_avg_grad = 1.1177641153335571, avg_norm_grad = 6.137065410614014,                  max_norm_grad = 10.153338432312012
round 102: local lr = 0.013282980769872665, norm_avg_grad = 1.071505069732666, avg_norm_grad = 6.096560478210449,                  max_norm_grad = 10.070273399353027
round 103: local lr = 0.011757250875234604, norm_avg_grad = 0.9487792253494263, avg_norm_grad = 6.098816871643066,                  max_norm_grad = 9.850311279296875
round 104: local lr = 0.012099413201212883, norm_avg_grad = 0.9814332723617554, avg_norm_grad = 6.130313396453857,                  max_norm_grad = 10.035453796386719

>>> Round:  105 / Acc: 87.703% / Loss: 0.4135 /Time: 5.31s
======================================================================================================

= Test = round: 105 / acc: 88.980% / loss: 0.3825 / Time: 0.94s
======================================================================================================

round 105: local lr = 0.011957859620451927, norm_avg_grad = 0.969363272190094, avg_norm_grad = 6.126596927642822,                  max_norm_grad = 9.98487663269043
round 106: local lr = 0.01309563871473074, norm_avg_grad = 1.0615025758743286, avg_norm_grad = 6.1260504722595215,                  max_norm_grad = 9.981881141662598
round 107: local lr = 0.01306123472750187, norm_avg_grad = 1.0452446937561035, avg_norm_grad = 6.048113822937012,                  max_norm_grad = 9.88649845123291
round 108: local lr = 0.012704373337328434, norm_avg_grad = 1.0178498029708862, avg_norm_grad = 6.05503511428833,                  max_norm_grad = 9.943764686584473
round 109: local lr = 0.013391759246587753, norm_avg_grad = 1.063087821006775, avg_norm_grad = 5.999536991119385,                  max_norm_grad = 9.967613220214844

>>> Round:  110 / Acc: 87.970% / Loss: 0.4021 /Time: 5.32s
======================================================================================================

= Test = round: 110 / acc: 89.210% / loss: 0.3712 / Time: 1.03s
======================================================================================================

round 110: local lr = 0.01265293825417757, norm_avg_grad = 0.9959575533866882, avg_norm_grad = 5.948886394500732,                  max_norm_grad = 9.764806747436523
round 111: local lr = 0.01195451058447361, norm_avg_grad = 0.9362162947654724, avg_norm_grad = 5.918758392333984,                  max_norm_grad = 9.679835319519043
round 112: local lr = 0.012228060513734818, norm_avg_grad = 0.9575109481811523, avg_norm_grad = 5.917964935302734,                  max_norm_grad = 9.775755882263184
round 113: local lr = 0.012386815622448921, norm_avg_grad = 0.968967080116272, avg_norm_grad = 5.912015438079834,                  max_norm_grad = 9.761624336242676
round 114: local lr = 0.012291775085031986, norm_avg_grad = 0.9542820453643799, avg_norm_grad = 5.867436408996582,                  max_norm_grad = 9.68115234375

>>> Round:  115 / Acc: 88.332% / Loss: 0.3891 /Time: 4.30s
======================================================================================================

= Test = round: 115 / acc: 89.590% / loss: 0.3585 / Time: 0.87s
======================================================================================================

round 115: local lr = 0.012864349409937859, norm_avg_grad = 0.9994821548461914, avg_norm_grad = 5.871829509735107,                  max_norm_grad = 9.812614440917969
round 116: local lr = 0.012639528140425682, norm_avg_grad = 0.9740315675735474, avg_norm_grad = 5.824094295501709,                  max_norm_grad = 9.74885082244873
round 117: local lr = 0.012705656699836254, norm_avg_grad = 0.9841732978820801, avg_norm_grad = 5.85410737991333,                  max_norm_grad = 9.781956672668457
round 118: local lr = 0.012568042613565922, norm_avg_grad = 0.9700253009796143, avg_norm_grad = 5.8331298828125,                  max_norm_grad = 9.718517303466797
round 119: local lr = 0.013215499930083752, norm_avg_grad = 1.0169028043746948, avg_norm_grad = 5.815433025360107,                  max_norm_grad = 9.677720069885254

>>> Round:  120 / Acc: 88.544% / Loss: 0.3788 /Time: 4.29s
======================================================================================================

= Test = round: 120 / acc: 89.770% / loss: 0.3488 / Time: 0.89s
======================================================================================================

round 120: local lr = 0.01349589228630066, norm_avg_grad = 1.0315051078796387, avg_norm_grad = 5.776382923126221,                  max_norm_grad = 9.747471809387207
round 121: local lr = 0.014370880089700222, norm_avg_grad = 1.0767719745635986, avg_norm_grad = 5.662739276885986,                  max_norm_grad = 9.593818664550781
round 122: local lr = 0.012698535807430744, norm_avg_grad = 0.9406861662864685, avg_norm_grad = 5.598572731018066,                  max_norm_grad = 9.252766609191895
round 123: local lr = 0.011494297534227371, norm_avg_grad = 0.8556651473045349, avg_norm_grad = 5.626101970672607,                  max_norm_grad = 9.227591514587402
round 124: local lr = 0.011194266378879547, norm_avg_grad = 0.8356558084487915, avg_norm_grad = 5.641804218292236,                  max_norm_grad = 9.233758926391602

>>> Round:  125 / Acc: 89.031% / Loss: 0.3646 /Time: 4.37s
======================================================================================================

= Test = round: 125 / acc: 90.060% / loss: 0.3362 / Time: 0.84s
======================================================================================================

round 125: local lr = 0.011893050745129585, norm_avg_grad = 0.8961273431777954, avg_norm_grad = 5.6945929527282715,                  max_norm_grad = 9.433432579040527
round 126: local lr = 0.012242242693901062, norm_avg_grad = 0.9264811873435974, avg_norm_grad = 5.719549655914307,                  max_norm_grad = 9.59327507019043
round 127: local lr = 0.01260828785598278, norm_avg_grad = 0.9483566880226135, avg_norm_grad = 5.684625148773193,                  max_norm_grad = 9.630172729492188
round 128: local lr = 0.012358475476503372, norm_avg_grad = 0.9186573028564453, avg_norm_grad = 5.617910861968994,                  max_norm_grad = 9.468743324279785
round 129: local lr = 0.012282260693609715, norm_avg_grad = 0.9123547673225403, avg_norm_grad = 5.613990306854248,                  max_norm_grad = 9.523187637329102

>>> Round:  130 / Acc: 89.201% / Loss: 0.3561 /Time: 4.37s
======================================================================================================

= Test = round: 130 / acc: 90.230% / loss: 0.3287 / Time: 0.84s
======================================================================================================

round 130: local lr = 0.01285021286457777, norm_avg_grad = 0.9563011527061462, avg_norm_grad = 5.624327182769775,                  max_norm_grad = 9.724825859069824
round 131: local lr = 0.01235939096659422, norm_avg_grad = 0.9068759083747864, avg_norm_grad = 5.54545259475708,                  max_norm_grad = 9.477827072143555
round 132: local lr = 0.013053853064775467, norm_avg_grad = 0.9606855511665344, avg_norm_grad = 5.561971187591553,                  max_norm_grad = 9.605627059936523
round 133: local lr = 0.011715571396052837, norm_avg_grad = 0.8447648882865906, avg_norm_grad = 5.449524402618408,                  max_norm_grad = 9.001025199890137
round 134: local lr = 0.012694715522229671, norm_avg_grad = 0.9158892631530762, avg_norm_grad = 5.452631950378418,                  max_norm_grad = 9.052714347839355

>>> Round:  135 / Acc: 89.563% / Loss: 0.3480 /Time: 4.72s
======================================================================================================

= Test = round: 135 / acc: 90.600% / loss: 0.3207 / Time: 0.83s
======================================================================================================

round 135: local lr = 0.01217187475413084, norm_avg_grad = 0.8730266094207764, avg_norm_grad = 5.420710563659668,                  max_norm_grad = 8.999798774719238
round 136: local lr = 0.010635484009981155, norm_avg_grad = 0.7612245678901672, avg_norm_grad = 5.409308910369873,                  max_norm_grad = 8.842779159545898
round 137: local lr = 0.010357929393649101, norm_avg_grad = 0.7478042244911194, avg_norm_grad = 5.456336498260498,                  max_norm_grad = 8.962138175964355
round 138: local lr = 0.011548326350748539, norm_avg_grad = 0.8415157794952393, avg_norm_grad = 5.5071821212768555,                  max_norm_grad = 9.281100273132324
round 139: local lr = 0.012527852319180965, norm_avg_grad = 0.9095636606216431, avg_norm_grad = 5.487097263336182,                  max_norm_grad = 9.400784492492676

>>> Round:  140 / Acc: 89.784% / Loss: 0.3379 /Time: 4.33s
======================================================================================================

= Test = round: 140 / acc: 90.740% / loss: 0.3115 / Time: 0.85s
======================================================================================================

round 140: local lr = 0.012502551078796387, norm_avg_grad = 0.8948656320571899, avg_norm_grad = 5.409354209899902,                  max_norm_grad = 9.200135231018066
round 141: local lr = 0.012255209498107433, norm_avg_grad = 0.8753370046615601, avg_norm_grad = 5.398097991943359,                  max_norm_grad = 9.09560489654541
round 142: local lr = 0.011970411986112595, norm_avg_grad = 0.8548737168312073, avg_norm_grad = 5.397331237792969,                  max_norm_grad = 8.978373527526855
round 143: local lr = 0.01235954463481903, norm_avg_grad = 0.8816163539886475, avg_norm_grad = 5.390926361083984,                  max_norm_grad = 9.051032066345215
round 144: local lr = 0.012120380997657776, norm_avg_grad = 0.8513591289520264, avg_norm_grad = 5.308633327484131,                  max_norm_grad = 8.916386604309082

>>> Round:  145 / Acc: 90.059% / Loss: 0.3283 /Time: 4.27s
======================================================================================================

= Test = round: 145 / acc: 91.050% / loss: 0.3021 / Time: 0.80s
======================================================================================================

round 145: local lr = 0.011938894167542458, norm_avg_grad = 0.8404660820960999, avg_norm_grad = 5.320375919342041,                  max_norm_grad = 8.921025276184082
round 146: local lr = 0.011561115272343159, norm_avg_grad = 0.8160446882247925, avg_norm_grad = 5.334582328796387,                  max_norm_grad = 8.835441589355469
round 147: local lr = 0.011801491491496563, norm_avg_grad = 0.8351796865463257, avg_norm_grad = 5.348465919494629,                  max_norm_grad = 8.944504737854004
round 148: local lr = 0.01302389521151781, norm_avg_grad = 0.9202727675437927, avg_norm_grad = 5.340253829956055,                  max_norm_grad = 9.114396095275879
round 149: local lr = 0.01344708725810051, norm_avg_grad = 0.9412843585014343, avg_norm_grad = 5.290282249450684,                  max_norm_grad = 9.080060958862305

>>> Round:  150 / Acc: 90.247% / Loss: 0.3226 /Time: 4.23s
======================================================================================================

= Test = round: 150 / acc: 91.030% / loss: 0.2976 / Time: 0.82s
======================================================================================================

round 150: local lr = 0.012655909173190594, norm_avg_grad = 0.8694273233413696, avg_norm_grad = 5.191897869110107,                  max_norm_grad = 8.806021690368652
round 151: local lr = 0.012670488096773624, norm_avg_grad = 0.8700332641601562, avg_norm_grad = 5.18953800201416,                  max_norm_grad = 8.818964958190918
round 152: local lr = 0.01279718242585659, norm_avg_grad = 0.8756181001663208, avg_norm_grad = 5.171143531799316,                  max_norm_grad = 8.878375053405762
round 153: local lr = 0.01327233761548996, norm_avg_grad = 0.9116482734680176, avg_norm_grad = 5.191180229187012,                  max_norm_grad = 8.98724365234375
round 154: local lr = 0.013463781215250492, norm_avg_grad = 0.9186511039733887, avg_norm_grad = 5.156674861907959,                  max_norm_grad = 8.9015531539917

>>> Round:  155 / Acc: 90.504% / Loss: 0.3155 /Time: 4.36s
======================================================================================================

= Test = round: 155 / acc: 91.410% / loss: 0.2904 / Time: 0.81s
======================================================================================================

round 155: local lr = 0.013010425493121147, norm_avg_grad = 0.8741758465766907, avg_norm_grad = 5.078009605407715,                  max_norm_grad = 8.726616859436035
round 156: local lr = 0.012949207797646523, norm_avg_grad = 0.8712677955627441, avg_norm_grad = 5.085043430328369,                  max_norm_grad = 8.733901977539062
round 157: local lr = 0.011935820803046227, norm_avg_grad = 0.8027703762054443, avg_norm_grad = 5.083060264587402,                  max_norm_grad = 8.603531837463379
round 158: local lr = 0.01144719123840332, norm_avg_grad = 0.770067036151886, avg_norm_grad = 5.084120273590088,                  max_norm_grad = 8.502116203308105
round 159: local lr = 0.011420974507927895, norm_avg_grad = 0.7713677883148193, avg_norm_grad = 5.104398250579834,                  max_norm_grad = 8.537199974060059

>>> Round:  160 / Acc: 90.747% / Loss: 0.3040 /Time: 4.29s
======================================================================================================

= Test = round: 160 / acc: 91.530% / loss: 0.2803 / Time: 0.84s
======================================================================================================

round 160: local lr = 0.011850412003695965, norm_avg_grad = 0.8040304183959961, avg_norm_grad = 5.1277313232421875,                  max_norm_grad = 8.662344932556152
round 161: local lr = 0.012089519761502743, norm_avg_grad = 0.8150126338005066, avg_norm_grad = 5.094968318939209,                  max_norm_grad = 8.605051040649414
round 162: local lr = 0.012628798373043537, norm_avg_grad = 0.8450925946235657, avg_norm_grad = 5.057413578033447,                  max_norm_grad = 8.480000495910645
round 163: local lr = 0.012385374866425991, norm_avg_grad = 0.8227800726890564, avg_norm_grad = 5.020660400390625,                  max_norm_grad = 8.370185852050781
round 164: local lr = 0.012245393358170986, norm_avg_grad = 0.8157066702842712, avg_norm_grad = 5.034397602081299,                  max_norm_grad = 8.40670108795166

>>> Round:  165 / Acc: 90.924% / Loss: 0.2974 /Time: 4.37s
======================================================================================================

= Test = round: 165 / acc: 91.720% / loss: 0.2742 / Time: 0.81s
======================================================================================================

round 165: local lr = 0.012273663654923439, norm_avg_grad = 0.8206607699394226, avg_norm_grad = 5.053307056427002,                  max_norm_grad = 8.403882026672363
round 166: local lr = 0.011853644624352455, norm_avg_grad = 0.7896769642829895, avg_norm_grad = 5.034818172454834,                  max_norm_grad = 8.254435539245605
round 167: local lr = 0.012529920786619186, norm_avg_grad = 0.8349867463111877, avg_norm_grad = 5.036368370056152,                  max_norm_grad = 8.342368125915527
round 168: local lr = 0.012403941713273525, norm_avg_grad = 0.820742130279541, avg_norm_grad = 5.000727653503418,                  max_norm_grad = 8.35157299041748
round 169: local lr = 0.012192735448479652, norm_avg_grad = 0.8004419207572937, avg_norm_grad = 4.961521625518799,                  max_norm_grad = 8.2630615234375

>>> Round:  170 / Acc: 91.168% / Loss: 0.2913 /Time: 4.27s
======================================================================================================

= Test = round: 170 / acc: 91.970% / loss: 0.2678 / Time: 0.82s
======================================================================================================

round 170: local lr = 0.012285943143069744, norm_avg_grad = 0.7997567057609558, avg_norm_grad = 4.919665813446045,                  max_norm_grad = 8.178135871887207
round 171: local lr = 0.012329542078077793, norm_avg_grad = 0.8062995672225952, avg_norm_grad = 4.942375183105469,                  max_norm_grad = 8.25650405883789
round 172: local lr = 0.01213650219142437, norm_avg_grad = 0.7857329845428467, avg_norm_grad = 4.892914772033691,                  max_norm_grad = 8.126877784729004
round 173: local lr = 0.01280560065060854, norm_avg_grad = 0.8247852325439453, avg_norm_grad = 4.867737293243408,                  max_norm_grad = 8.20702838897705
round 174: local lr = 0.013315186835825443, norm_avg_grad = 0.8533260226249695, avg_norm_grad = 4.843440055847168,                  max_norm_grad = 8.21957778930664

>>> Round:  175 / Acc: 91.389% / Loss: 0.2864 /Time: 4.29s
======================================================================================================

= Test = round: 175 / acc: 92.130% / loss: 0.2634 / Time: 0.85s
======================================================================================================

round 175: local lr = 0.012737617827951908, norm_avg_grad = 0.8088163137435913, avg_norm_grad = 4.79896879196167,                  max_norm_grad = 8.188902854919434
round 176: local lr = 0.011570650152862072, norm_avg_grad = 0.7360662221908569, avg_norm_grad = 4.807788372039795,                  max_norm_grad = 8.056174278259277
round 177: local lr = 0.011320246383547783, norm_avg_grad = 0.7199289798736572, avg_norm_grad = 4.806400775909424,                  max_norm_grad = 7.953983306884766
round 178: local lr = 0.011449454352259636, norm_avg_grad = 0.7297917604446411, avg_norm_grad = 4.817263126373291,                  max_norm_grad = 8.024534225463867
round 179: local lr = 0.011551633477210999, norm_avg_grad = 0.7337539196014404, avg_norm_grad = 4.800574779510498,                  max_norm_grad = 7.997414588928223

>>> Round:  180 / Acc: 91.605% / Loss: 0.2773 /Time: 4.21s
======================================================================================================

= Test = round: 180 / acc: 92.380% / loss: 0.2547 / Time: 0.86s
======================================================================================================

round 180: local lr = 0.011486711911857128, norm_avg_grad = 0.7292672991752625, avg_norm_grad = 4.798187732696533,                  max_norm_grad = 7.964897632598877
round 181: local lr = 0.01233817171305418, norm_avg_grad = 0.778572678565979, avg_norm_grad = 4.769079208374023,                  max_norm_grad = 7.895431041717529
round 182: local lr = 0.011141634546220303, norm_avg_grad = 0.7037696242332458, avg_norm_grad = 4.773839473724365,                  max_norm_grad = 7.647604465484619
round 183: local lr = 0.011486710980534554, norm_avg_grad = 0.7274542450904846, avg_norm_grad = 4.786259174346924,                  max_norm_grad = 7.75574254989624
round 184: local lr = 0.010605563409626484, norm_avg_grad = 0.6734080910682678, avg_norm_grad = 4.798779487609863,                  max_norm_grad = 7.6847381591796875

>>> Round:  185 / Acc: 91.819% / Loss: 0.2700 /Time: 4.23s
======================================================================================================

= Test = round: 185 / acc: 92.520% / loss: 0.2479 / Time: 0.80s
======================================================================================================

round 185: local lr = 0.010849050246179104, norm_avg_grad = 0.6877373456954956, avg_norm_grad = 4.790899753570557,                  max_norm_grad = 7.739297866821289
round 186: local lr = 0.01108511257916689, norm_avg_grad = 0.7047311663627625, avg_norm_grad = 4.804736614227295,                  max_norm_grad = 7.752223014831543
round 187: local lr = 0.011823736131191254, norm_avg_grad = 0.7534674406051636, avg_norm_grad = 4.816105365753174,                  max_norm_grad = 7.847826957702637
round 188: local lr = 0.012606719508767128, norm_avg_grad = 0.7981895804405212, avg_norm_grad = 4.785090446472168,                  max_norm_grad = 7.9109063148498535
round 189: local lr = 0.012239702045917511, norm_avg_grad = 0.7654416561126709, avg_norm_grad = 4.726366996765137,                  max_norm_grad = 7.774277687072754

>>> Round:  190 / Acc: 91.943% / Loss: 0.2663 /Time: 4.48s
======================================================================================================

= Test = round: 190 / acc: 92.570% / loss: 0.2442 / Time: 0.82s
======================================================================================================

round 190: local lr = 0.012108123861253262, norm_avg_grad = 0.7561284899711609, avg_norm_grad = 4.719597816467285,                  max_norm_grad = 7.755306243896484
round 191: local lr = 0.012399590574204922, norm_avg_grad = 0.7739747166633606, avg_norm_grad = 4.717432022094727,                  max_norm_grad = 7.702251434326172
round 192: local lr = 0.01230063196271658, norm_avg_grad = 0.7596175074577332, avg_norm_grad = 4.667171478271484,                  max_norm_grad = 7.706397533416748
round 193: local lr = 0.012095085345208645, norm_avg_grad = 0.7405776977539062, avg_norm_grad = 4.62751579284668,                  max_norm_grad = 7.59676456451416
round 194: local lr = 0.012231879867613316, norm_avg_grad = 0.7485378980636597, avg_norm_grad = 4.624947547912598,                  max_norm_grad = 7.614073276519775

>>> Round:  195 / Acc: 92.066% / Loss: 0.2629 /Time: 4.36s
======================================================================================================

= Test = round: 195 / acc: 92.770% / loss: 0.2407 / Time: 0.81s
======================================================================================================

round 195: local lr = 0.013383147306740284, norm_avg_grad = 0.8154871463775635, avg_norm_grad = 4.60516357421875,                  max_norm_grad = 7.749269008636475
round 196: local lr = 0.014189782552421093, norm_avg_grad = 0.8518036603927612, avg_norm_grad = 4.536803722381592,                  max_norm_grad = 7.666406154632568
round 197: local lr = 0.012972431257367134, norm_avg_grad = 0.7731311917304993, avg_norm_grad = 4.504203796386719,                  max_norm_grad = 7.404234409332275
round 198: local lr = 0.012382990680634975, norm_avg_grad = 0.7332426905632019, avg_norm_grad = 4.47515869140625,                  max_norm_grad = 7.413600444793701
round 199: local lr = 0.012431311421096325, norm_avg_grad = 0.7366220951080322, avg_norm_grad = 4.47830867767334,                  max_norm_grad = 7.437394618988037

>>> Round:  200 / Acc: 92.312% / Loss: 0.2562 /Time: 4.40s
======================================================================================================

= Test = round: 200 / acc: 93.020% / loss: 0.2346 / Time: 0.81s
======================================================================================================

>>> Training model_ft
Epoch: 001, Train_loss: 1.1463, Train_acc: 0.6484, Test_loss: 1.1251, Test_acc: 0.6609
Epoch: 006, Train_loss: 0.9076, Train_acc: 0.7186, Test_loss: 0.8988, Test_acc: 0.7235
Epoch: 011, Train_loss: 0.8458, Train_acc: 0.7363, Test_loss: 0.8508, Test_acc: 0.7371
Epoch: 016, Train_loss: 0.8236, Train_acc: 0.7396, Test_loss: 0.8444, Test_acc: 0.7364
Epoch: 021, Train_loss: 0.7813, Train_acc: 0.7526, Test_loss: 0.8096, Test_acc: 0.7499
Epoch: 026, Train_loss: 0.7549, Train_acc: 0.7609, Test_loss: 0.7972, Test_acc: 0.7480
Epoch: 031, Train_loss: 0.7580, Train_acc: 0.7580, Test_loss: 0.8016, Test_acc: 0.7467
Epoch: 036, Train_loss: 0.7369, Train_acc: 0.7630, Test_loss: 0.7950, Test_acc: 0.7499
Epoch: 041, Train_loss: 0.7237, Train_acc: 0.7675, Test_loss: 0.7919, Test_acc: 0.7521
Epoch: 046, Train_loss: 0.7263, Train_acc: 0.7651, Test_loss: 0.7991, Test_acc: 0.7477
Epoch: 051, Train_loss: 0.7073, Train_acc: 0.7707, Test_loss: 0.7907, Test_acc: 0.7499
Epoch: 056, Train_loss: 0.7065, Train_acc: 0.7724, Test_loss: 0.7950, Test_acc: 0.7530
Epoch: 061, Train_loss: 0.6857, Train_acc: 0.7781, Test_loss: 0.7811, Test_acc: 0.7532
Epoch: 066, Train_loss: 0.6743, Train_acc: 0.7821, Test_loss: 0.7791, Test_acc: 0.7564
Epoch: 071, Train_loss: 0.6739, Train_acc: 0.7819, Test_loss: 0.7821, Test_acc: 0.7520
Epoch: 076, Train_loss: 0.6753, Train_acc: 0.7804, Test_loss: 0.7832, Test_acc: 0.7551
Epoch: 081, Train_loss: 0.6651, Train_acc: 0.7838, Test_loss: 0.7786, Test_acc: 0.7546
Epoch: 086, Train_loss: 0.6672, Train_acc: 0.7832, Test_loss: 0.7822, Test_acc: 0.7556
Epoch: 091, Train_loss: 0.6575, Train_acc: 0.7847, Test_loss: 0.7751, Test_acc: 0.7574
Epoch: 096, Train_loss: 0.6610, Train_acc: 0.7843, Test_loss: 0.7916, Test_acc: 0.7532
Epoch: 101, Train_loss: 0.6509, Train_acc: 0.7881, Test_loss: 0.7773, Test_acc: 0.7542
Epoch: 106, Train_loss: 0.6500, Train_acc: 0.7879, Test_loss: 0.7843, Test_acc: 0.7541
Epoch: 111, Train_loss: 0.6469, Train_acc: 0.7889, Test_loss: 0.7804, Test_acc: 0.7551
Epoch: 116, Train_loss: 0.6549, Train_acc: 0.7864, Test_loss: 0.7971, Test_acc: 0.7534
Epoch: 121, Train_loss: 0.6393, Train_acc: 0.7903, Test_loss: 0.7796, Test_acc: 0.7566
Fine-tuning early stopped. Model saved at ./models/ft_checkpoints/20230928000440_model_ft.pt.
Model saved at ./models/ft_checkpoints/20230928000440_model_ft.pt.
>>> Fine-tuning done!
>>> Evaluating model_source_only
model_ft: [0.6387439944997032, 0.7924611447263605, 0.7752288971069375, 0.7576935896011554]
model_source_only: [2.2211180024222923, 0.4449246622938594, 2.24070886467155, 0.44695033885123875]
fl_test_acc_mean 0.9296
model_source_only_test_acc_mean 0.44695033885123875
model_ft_test_acc_mean 0.7576935896011554
