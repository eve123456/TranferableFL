{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import importlib\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from src.utils.worker_utils import read_data\n",
    "from config import OPTIMIZERS, DATASETS, MODEL_PARAMS, TRAINERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_options():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--algo',\n",
    "                        help='name of trainer;',\n",
    "                        type=str,\n",
    "                        choices=OPTIMIZERS,\n",
    "                        default='fedavg4')\n",
    "    parser.add_argument('--dataset',\n",
    "                        help='name of dataset;',\n",
    "                        type=str,\n",
    "                        default='mnist_all_data_1_random_niid')\n",
    "    parser.add_argument('--finetune_dataset',\n",
    "                        help='name of finetune dataset;',\n",
    "                        type=str,\n",
    "                        default='SVHN')\n",
    "    parser.add_argument('--finetune_lr',\n",
    "                        help='lr for finetune;',\n",
    "                        type=float,\n",
    "                        default=0.01)\n",
    "    parser.add_argument('--finetune_wd',\n",
    "                        help='weight decay for finetune;',\n",
    "                        type=float,\n",
    "                        default=0.0)\n",
    "    parser.add_argument('--finetune_epochs',\n",
    "                        help='epochs for finetune;',\n",
    "                        type=int,\n",
    "                        default=100)\n",
    "    parser.add_argument('--model',\n",
    "                        help='name of model;',\n",
    "                        type=str,\n",
    "                        default='cnn')\n",
    "    parser.add_argument('--wd',\n",
    "                        help='weight decay parameter;',\n",
    "                        type=float,\n",
    "                        default=0.001)\n",
    "    parser.add_argument('--gpu',\n",
    "                        action='store_true',\n",
    "                        default=False,\n",
    "                        help='use gpu (default: False)')\n",
    "    parser.add_argument('--noprint',\n",
    "                        action='store_true',\n",
    "                        default=False,\n",
    "                        help='whether to print inner result (default: False)')\n",
    "    parser.add_argument('--noaverage',\n",
    "                        action='store_true',\n",
    "                        default=False,\n",
    "                        help='whether to only average local solutions (default: True)')\n",
    "    parser.add_argument('--device',\n",
    "                        help='selected CUDA device',\n",
    "                        default=0,\n",
    "                        type=int)\n",
    "    parser.add_argument('--num_round',\n",
    "                        help='number of rounds to simulate;',\n",
    "                        type=int,\n",
    "                        default=10)\n",
    "    parser.add_argument('--eval_every',\n",
    "                        help='evaluate every ____ rounds;',\n",
    "                        type=int,\n",
    "                        default=5)\n",
    "    parser.add_argument('--clients_per_round',\n",
    "                        help='number of clients trained per round;',\n",
    "                        type=int,\n",
    "                        default=10)\n",
    "    parser.add_argument('--batch_size',\n",
    "                        help='batch size when clients train on data;',\n",
    "                        type=int,\n",
    "                        default=64)\n",
    "    parser.add_argument('--num_epoch',\n",
    "                        help='number of epochs when clients train on data;',\n",
    "                        type=int,\n",
    "                        default=5)\n",
    "    parser.add_argument('--lr',\n",
    "                        help='learning rate for inner solver;',\n",
    "                        type=float,\n",
    "                        default=0.1)\n",
    "    parser.add_argument('--seed',\n",
    "                        help='seed for randomness;',\n",
    "                        type=int,\n",
    "                        default=0)\n",
    "    parser.add_argument('--dis',\n",
    "                        help='add more information;',\n",
    "                        type=str,\n",
    "                        default='')\n",
    "    parsed = parser.parse_args([])\n",
    "    options = parsed.__dict__\n",
    "    options['gpu'] = options['gpu'] and torch.cuda.is_available()\n",
    "\n",
    "    # Set seeds\n",
    "    np.random.seed(1 + options['seed'])\n",
    "    torch.manual_seed(12 + options['seed'])\n",
    "    if options['gpu']:\n",
    "        torch.cuda.manual_seed_all(123 + options['seed'])\n",
    "\n",
    "    # read data\n",
    "    idx = options['dataset'].find(\"_\")\n",
    "    if idx != -1:\n",
    "        dataset_name, sub_data = options['dataset'][:idx], options['dataset'][idx+1:]\n",
    "    else:\n",
    "        dataset_name, sub_data = options['dataset'], None\n",
    "    assert dataset_name in DATASETS, \"{} not in dataset {}!\".format(dataset_name, DATASETS)\n",
    "\n",
    "    # Add model arguments\n",
    "    options.update(MODEL_PARAMS(dataset_name, options['model']))\n",
    "\n",
    "    # Load selected trainer\n",
    "    trainer_path = 'src.trainers.%s' % options['algo']\n",
    "    mod = importlib.import_module(trainer_path)\n",
    "    trainer_class = getattr(mod, TRAINERS[options['algo']])\n",
    "\n",
    "    # Print arguments and return\n",
    "    max_length = max([len(key) for key in options.keys()])\n",
    "    fmt_string = '\\t%' + str(max_length) + 's : %s'\n",
    "    print('>>> Arguments:')\n",
    "    for keyPair in sorted(options.items()):\n",
    "        print(fmt_string % keyPair)\n",
    "\n",
    "    return options, trainer_class, dataset_name, sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Arguments:\n",
      "\t             algo : fedavg4\n",
      "\t       batch_size : 64\n",
      "\tclients_per_round : 10\n",
      "\t          dataset : mnist_all_data_1_random_niid\n",
      "\t           device : 0\n",
      "\t              dis : \n",
      "\t       eval_every : 5\n",
      "\t finetune_dataset : SVHN\n",
      "\t  finetune_epochs : 100\n",
      "\t      finetune_lr : 0.01\n",
      "\t      finetune_wd : 0.0\n",
      "\t              gpu : False\n",
      "\t      input_shape : (1, 28, 28)\n",
      "\t               lr : 0.1\n",
      "\t            model : cnn\n",
      "\t        noaverage : False\n",
      "\t          noprint : False\n",
      "\t        num_class : 10\n",
      "\t        num_epoch : 5\n",
      "\t        num_round : 10\n",
      "\t             seed : 0\n",
      "\t               wd : 0.001\n",
      ">>> Read data from:\n",
      "     ./data/mnist/data/train/all_data_1_random_niid.pkl\n",
      "     ./data/mnist/data/test/all_data_1_random_niid.pkl\n"
     ]
    }
   ],
   "source": [
    "# Parse command line arguments\n",
    "options, trainer_class, dataset_name, sub_data = read_options()\n",
    "\n",
    "train_path = os.path.join('./data', dataset_name, 'data', 'train')\n",
    "test_path = os.path.join('./data', dataset_name, 'data', 'test')\n",
    "\n",
    "# `dataset` is a tuple like (cids, groups, train_data, test_data)\n",
    "all_data_info = read_data(train_path, test_path, sub_data)\n",
    "\n",
    "# # Call appropriate trainer\n",
    "# trainer = trainer_class(options, all_data_info)\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.torch_utils import get_flat_grad, get_state_dict, get_flat_params_from, set_flat_params_to\n",
    "from src.models.model import choose_model\n",
    "\n",
    "# FL training finish here, save the latest server model\n",
    "# flat_model_param = trainer.latest_model\n",
    "# PATH = f\"./models/{options['model']}_{dataset_name}_{options['algo']}\"\n",
    "# torch.save(flat_model_param, PATH)\n",
    "\n",
    "\n",
    "# # This is the final flattened model params\n",
    "# flat_model_params = trainer.latest_model\n",
    "PATH = f\"./models/{options['model']}_{dataset_name}_{options['algo']}\"\n",
    "flat_model_params = torch.load(PATH)\n",
    "# Initialize a new model\n",
    "model = choose_model(options)\n",
    "# Assign model params\n",
    "set_flat_params_to(model, flat_model_params)\n",
    "# Now model is set with flat_model_params\n",
    "\n",
    "# Start fine-tuning below\n",
    "# First, freeze all but last layer\n",
    "for mod in model.children():\n",
    "    for params in mod.parameters():\n",
    "        params.requires_grad = False\n",
    "\n",
    "for params in mod.parameters():\n",
    "    params.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/svhn/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/svhn/test_32x32.mat\n",
      "Epoch:001, Trn_loss:0.0433, Trn_acc:0.3430, Tst_loss:0.1104, Tst_acc:0.3532\n",
      "Epoch:002, Trn_loss:0.0399, Trn_acc:0.3838, Tst_loss:0.1030, Tst_acc:0.3989\n",
      "Epoch:003, Trn_loss:0.0382, Trn_acc:0.4332, Tst_loss:0.0983, Tst_acc:0.4451\n",
      "Epoch:004, Trn_loss:0.0368, Trn_acc:0.4748, Tst_loss:0.0916, Tst_acc:0.4874\n",
      "Epoch:005, Trn_loss:0.0356, Trn_acc:0.4918, Tst_loss:0.0907, Tst_acc:0.5067\n",
      "Epoch:006, Trn_loss:0.0347, Trn_acc:0.5227, Tst_loss:0.0874, Tst_acc:0.5400\n",
      "Epoch:007, Trn_loss:0.0330, Trn_acc:0.5410, Tst_loss:0.0837, Tst_acc:0.5540\n",
      "Epoch:008, Trn_loss:0.0329, Trn_acc:0.5489, Tst_loss:0.0811, Tst_acc:0.5675\n",
      "Epoch:009, Trn_loss:0.0316, Trn_acc:0.5416, Tst_loss:0.0783, Tst_acc:0.5612\n",
      "Epoch:010, Trn_loss:0.0306, Trn_acc:0.5733, Tst_loss:0.0774, Tst_acc:0.5935\n",
      "Epoch:011, Trn_loss:0.0303, Trn_acc:0.5854, Tst_loss:0.0774, Tst_acc:0.6011\n",
      "Epoch:012, Trn_loss:0.0299, Trn_acc:0.5906, Tst_loss:0.0762, Tst_acc:0.6083\n",
      "Epoch:013, Trn_loss:0.0300, Trn_acc:0.6092, Tst_loss:0.0771, Tst_acc:0.6249\n",
      "Epoch:014, Trn_loss:0.0291, Trn_acc:0.5931, Tst_loss:0.0764, Tst_acc:0.6143\n",
      "Epoch:015, Trn_loss:0.0284, Trn_acc:0.6105, Tst_loss:0.0729, Tst_acc:0.6240\n",
      "Epoch:016, Trn_loss:0.0285, Trn_acc:0.6082, Tst_loss:0.0707, Tst_acc:0.6294\n",
      "Epoch:017, Trn_loss:0.0283, Trn_acc:0.6279, Tst_loss:0.0704, Tst_acc:0.6457\n",
      "Epoch:018, Trn_loss:0.0270, Trn_acc:0.6198, Tst_loss:0.0710, Tst_acc:0.6390\n",
      "Epoch:019, Trn_loss:0.0275, Trn_acc:0.6265, Tst_loss:0.0733, Tst_acc:0.6404\n",
      "Epoch:020, Trn_loss:0.0276, Trn_acc:0.6404, Tst_loss:0.0670, Tst_acc:0.6591\n",
      "Epoch:021, Trn_loss:0.0261, Trn_acc:0.6378, Tst_loss:0.0686, Tst_acc:0.6541\n",
      "Epoch:022, Trn_loss:0.0273, Trn_acc:0.6414, Tst_loss:0.0665, Tst_acc:0.6580\n",
      "Epoch:023, Trn_loss:0.0262, Trn_acc:0.6399, Tst_loss:0.0672, Tst_acc:0.6574\n",
      "Epoch:024, Trn_loss:0.0263, Trn_acc:0.6486, Tst_loss:0.0674, Tst_acc:0.6653\n",
      "Epoch:025, Trn_loss:0.0257, Trn_acc:0.6532, Tst_loss:0.0664, Tst_acc:0.6693\n",
      "Epoch:026, Trn_loss:0.0261, Trn_acc:0.6575, Tst_loss:0.0642, Tst_acc:0.6756\n",
      "Epoch:027, Trn_loss:0.0257, Trn_acc:0.6480, Tst_loss:0.0647, Tst_acc:0.6644\n",
      "Epoch:028, Trn_loss:0.0247, Trn_acc:0.6610, Tst_loss:0.0635, Tst_acc:0.6776\n",
      "Epoch:029, Trn_loss:0.0247, Trn_acc:0.6631, Tst_loss:0.0629, Tst_acc:0.6790\n",
      "Epoch:030, Trn_loss:0.0251, Trn_acc:0.6620, Tst_loss:0.0598, Tst_acc:0.6756\n",
      "Epoch:031, Trn_loss:0.0256, Trn_acc:0.6646, Tst_loss:0.0622, Tst_acc:0.6783\n",
      "Epoch:032, Trn_loss:0.0247, Trn_acc:0.6682, Tst_loss:0.0664, Tst_acc:0.6863\n",
      "Epoch:033, Trn_loss:0.0250, Trn_acc:0.6753, Tst_loss:0.0634, Tst_acc:0.6901\n",
      "Epoch:034, Trn_loss:0.0249, Trn_acc:0.6756, Tst_loss:0.0633, Tst_acc:0.6921\n",
      "Epoch:035, Trn_loss:0.0257, Trn_acc:0.6719, Tst_loss:0.0629, Tst_acc:0.6862\n",
      "Epoch:036, Trn_loss:0.0249, Trn_acc:0.6798, Tst_loss:0.0614, Tst_acc:0.6966\n",
      "Epoch:037, Trn_loss:0.0242, Trn_acc:0.6796, Tst_loss:0.0629, Tst_acc:0.6943\n",
      "Epoch:038, Trn_loss:0.0249, Trn_acc:0.6701, Tst_loss:0.0606, Tst_acc:0.6849\n",
      "Epoch:039, Trn_loss:0.0237, Trn_acc:0.6784, Tst_loss:0.0627, Tst_acc:0.6936\n",
      "Epoch:040, Trn_loss:0.0251, Trn_acc:0.6812, Tst_loss:0.0617, Tst_acc:0.6966\n",
      "Epoch:041, Trn_loss:0.0228, Trn_acc:0.6806, Tst_loss:0.0598, Tst_acc:0.6961\n",
      "Epoch:042, Trn_loss:0.0233, Trn_acc:0.6793, Tst_loss:0.0590, Tst_acc:0.6946\n",
      "Epoch:043, Trn_loss:0.0235, Trn_acc:0.6863, Tst_loss:0.0606, Tst_acc:0.7000\n",
      "Epoch:044, Trn_loss:0.0233, Trn_acc:0.6896, Tst_loss:0.0598, Tst_acc:0.7078\n",
      "Epoch:045, Trn_loss:0.0238, Trn_acc:0.6860, Tst_loss:0.0596, Tst_acc:0.7030\n",
      "Epoch:046, Trn_loss:0.0233, Trn_acc:0.6915, Tst_loss:0.0602, Tst_acc:0.7042\n",
      "Epoch:047, Trn_loss:0.0236, Trn_acc:0.6935, Tst_loss:0.0593, Tst_acc:0.7060\n",
      "Epoch:048, Trn_loss:0.0233, Trn_acc:0.6895, Tst_loss:0.0632, Tst_acc:0.7039\n",
      "Epoch:049, Trn_loss:0.0228, Trn_acc:0.6957, Tst_loss:0.0588, Tst_acc:0.7049\n",
      "Epoch:050, Trn_loss:0.0235, Trn_acc:0.6929, Tst_loss:0.0624, Tst_acc:0.7062\n",
      "Epoch:051, Trn_loss:0.0224, Trn_acc:0.6918, Tst_loss:0.0576, Tst_acc:0.7039\n",
      "Epoch:052, Trn_loss:0.0227, Trn_acc:0.6977, Tst_loss:0.0572, Tst_acc:0.7115\n",
      "Epoch:053, Trn_loss:0.0221, Trn_acc:0.6955, Tst_loss:0.0580, Tst_acc:0.7099\n",
      "Epoch:054, Trn_loss:0.0234, Trn_acc:0.7031, Tst_loss:0.0580, Tst_acc:0.7184\n",
      "Epoch:055, Trn_loss:0.0231, Trn_acc:0.7008, Tst_loss:0.0568, Tst_acc:0.7139\n",
      "Epoch:056, Trn_loss:0.0217, Trn_acc:0.7016, Tst_loss:0.0576, Tst_acc:0.7158\n",
      "Epoch:057, Trn_loss:0.0228, Trn_acc:0.6999, Tst_loss:0.0595, Tst_acc:0.7151\n",
      "Epoch:058, Trn_loss:0.0216, Trn_acc:0.6987, Tst_loss:0.0551, Tst_acc:0.7119\n",
      "Epoch:059, Trn_loss:0.0231, Trn_acc:0.7049, Tst_loss:0.0604, Tst_acc:0.7178\n",
      "Epoch:060, Trn_loss:0.0220, Trn_acc:0.7034, Tst_loss:0.0570, Tst_acc:0.7175\n",
      "Epoch:061, Trn_loss:0.0227, Trn_acc:0.7016, Tst_loss:0.0586, Tst_acc:0.7152\n",
      "Epoch:062, Trn_loss:0.0220, Trn_acc:0.7065, Tst_loss:0.0544, Tst_acc:0.7170\n",
      "Epoch:063, Trn_loss:0.0218, Trn_acc:0.7059, Tst_loss:0.0573, Tst_acc:0.7205\n",
      "Epoch:064, Trn_loss:0.0222, Trn_acc:0.7099, Tst_loss:0.0584, Tst_acc:0.7221\n",
      "Epoch:065, Trn_loss:0.0225, Trn_acc:0.7060, Tst_loss:0.0553, Tst_acc:0.7206\n",
      "Epoch:066, Trn_loss:0.0223, Trn_acc:0.7103, Tst_loss:0.0598, Tst_acc:0.7221\n",
      "Epoch:067, Trn_loss:0.0214, Trn_acc:0.7090, Tst_loss:0.0574, Tst_acc:0.7185\n",
      "Epoch:068, Trn_loss:0.0226, Trn_acc:0.7110, Tst_loss:0.0579, Tst_acc:0.7246\n",
      "Epoch:069, Trn_loss:0.0207, Trn_acc:0.7107, Tst_loss:0.0590, Tst_acc:0.7225\n",
      "Epoch:070, Trn_loss:0.0215, Trn_acc:0.7073, Tst_loss:0.0571, Tst_acc:0.7210\n",
      "Epoch:071, Trn_loss:0.0224, Trn_acc:0.7132, Tst_loss:0.0572, Tst_acc:0.7244\n",
      "Epoch:072, Trn_loss:0.0220, Trn_acc:0.7152, Tst_loss:0.0538, Tst_acc:0.7267\n",
      "Epoch:073, Trn_loss:0.0217, Trn_acc:0.7108, Tst_loss:0.0567, Tst_acc:0.7225\n",
      "Epoch:074, Trn_loss:0.0212, Trn_acc:0.7102, Tst_loss:0.0554, Tst_acc:0.7221\n",
      "Epoch:075, Trn_loss:0.0220, Trn_acc:0.7134, Tst_loss:0.0578, Tst_acc:0.7247\n",
      "Epoch:076, Trn_loss:0.0214, Trn_acc:0.7107, Tst_loss:0.0583, Tst_acc:0.7235\n",
      "Epoch:077, Trn_loss:0.0224, Trn_acc:0.7161, Tst_loss:0.0566, Tst_acc:0.7259\n",
      "Epoch:078, Trn_loss:0.0216, Trn_acc:0.7176, Tst_loss:0.0596, Tst_acc:0.7284\n",
      "Epoch:079, Trn_loss:0.0224, Trn_acc:0.7160, Tst_loss:0.0562, Tst_acc:0.7293\n",
      "Epoch:080, Trn_loss:0.0215, Trn_acc:0.7161, Tst_loss:0.0552, Tst_acc:0.7288\n",
      "Epoch:081, Trn_loss:0.0217, Trn_acc:0.7171, Tst_loss:0.0588, Tst_acc:0.7286\n",
      "Epoch:082, Trn_loss:0.0232, Trn_acc:0.7209, Tst_loss:0.0549, Tst_acc:0.7333\n",
      "Epoch:083, Trn_loss:0.0222, Trn_acc:0.7158, Tst_loss:0.0568, Tst_acc:0.7266\n",
      "Epoch:084, Trn_loss:0.0211, Trn_acc:0.7210, Tst_loss:0.0533, Tst_acc:0.7313\n",
      "Epoch:085, Trn_loss:0.0215, Trn_acc:0.7166, Tst_loss:0.0573, Tst_acc:0.7294\n",
      "Epoch:086, Trn_loss:0.0211, Trn_acc:0.7226, Tst_loss:0.0562, Tst_acc:0.7322\n",
      "Epoch:087, Trn_loss:0.0220, Trn_acc:0.7193, Tst_loss:0.0566, Tst_acc:0.7307\n",
      "Epoch:088, Trn_loss:0.0208, Trn_acc:0.7236, Tst_loss:0.0575, Tst_acc:0.7349\n",
      "Epoch:089, Trn_loss:0.0224, Trn_acc:0.7248, Tst_loss:0.0572, Tst_acc:0.7354\n",
      "Epoch:090, Trn_loss:0.0220, Trn_acc:0.7189, Tst_loss:0.0545, Tst_acc:0.7292\n",
      "Epoch:091, Trn_loss:0.0217, Trn_acc:0.7204, Tst_loss:0.0553, Tst_acc:0.7290\n",
      "Epoch:092, Trn_loss:0.0214, Trn_acc:0.7214, Tst_loss:0.0519, Tst_acc:0.7316\n",
      "Epoch:093, Trn_loss:0.0211, Trn_acc:0.7229, Tst_loss:0.0555, Tst_acc:0.7333\n",
      "Epoch:094, Trn_loss:0.0205, Trn_acc:0.7229, Tst_loss:0.0526, Tst_acc:0.7336\n",
      "Epoch:095, Trn_loss:0.0202, Trn_acc:0.7239, Tst_loss:0.0539, Tst_acc:0.7347\n",
      "Epoch:096, Trn_loss:0.0210, Trn_acc:0.7222, Tst_loss:0.0531, Tst_acc:0.7331\n",
      "Epoch:097, Trn_loss:0.0206, Trn_acc:0.7231, Tst_loss:0.0504, Tst_acc:0.7326\n",
      "Epoch:098, Trn_loss:0.0208, Trn_acc:0.7247, Tst_loss:0.0555, Tst_acc:0.7351\n",
      "Epoch:099, Trn_loss:0.0210, Trn_acc:0.7235, Tst_loss:0.0541, Tst_acc:0.7309\n",
      "Epoch:100, Trn_loss:0.0205, Trn_acc:0.7270, Tst_loss:0.0524, Tst_acc:0.7390\n",
      "Finetune done\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# # Next fine-tune the model on svhn:\n",
    "\n",
    "device = torch.device(f\"cuda:{options['device']}\")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Prepare data\n",
    "data_path = './data/svhn'\n",
    "kwargs = {'num_workers': 16}\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "])\n",
    "trainset = torchvision.datasets.SVHN(root=data_path, split='train', download=True, transform=transform)\n",
    "# extraset = torchvision.datasets.SVHN(root=data_path, split='extra', download=True, transform=transform)\n",
    "# trainset = torch.utils.data.ConcatDataset([trainset, extraset])\n",
    "testset = torchvision.datasets.SVHN(root=data_path, split='test', download=True, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=options['batch_size']*32, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=options['batch_size']*32, shuffle=True, **kwargs)\n",
    "\n",
    "# Prepare model: just put it to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Prepare optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=options['finetune_lr'], weight_decay=options['finetune_wd']) \n",
    "\n",
    "def ft_train(model,optimizer,device,train_loader):\n",
    "    model.train()\n",
    "    for x,y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del pred\n",
    "\n",
    "def ft_eval(model,optimizer,device,data_loader):\n",
    "    model.eval()\n",
    "    acc, loss, total = 0, 0, 0\n",
    "    for x,y in data_loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        correct = predicted.eq(y).sum().item()\n",
    "        target_size = y.size(0)\n",
    "        loss += loss.item() * y.size(0)\n",
    "        acc += correct\n",
    "        total += target_size\n",
    "\n",
    "        del pred\n",
    "        \n",
    "    total_loss = loss/total\n",
    "    total_acc = acc/total\n",
    "    \n",
    "    return total_loss, total_acc\n",
    "\n",
    "# training loops\n",
    "results = torch.zeros((options['finetune_epochs'],4)) # train_loss, train_acc, test_loss, test_acc\n",
    "for epoch in range(options['finetune_epochs']):\n",
    "    # Train 1 epoch\n",
    "    ft_train(model,optimizer,device,train_loader)\n",
    "    \n",
    "    # Get train stats\n",
    "    results[epoch,0], results[epoch,1] = ft_eval(model,optimizer,device,train_loader)\n",
    "    \n",
    "    # Get test stats\n",
    "    results[epoch,2], results[epoch,3] = ft_eval(model,optimizer,device,test_loader)\n",
    "    \n",
    "    print(f\"Epoch:{epoch+1:03d}, Trn_loss:{results[epoch,0].item():.4f}, Trn_acc:{results[epoch,1].item():.4f}, Tst_loss:{results[epoch,2].item():.4f}, Tst_acc:{results[epoch,3].item():.4f}\")\n",
    "\n",
    "print(\"Finetune done\")\n",
    "# Now save the final model\n",
    "PATH = f\"./models/{options['model']}_{dataset_name}_{options['algo']}_finetune_{options['finetune_dataset']}\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73256\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(trainset):\n",
    "    continue\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:{options['device']}\")\n",
    "# model = model.to(device)\n",
    "# for param in model.parameters():\n",
    "#     print(param.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLT",
   "language": "python",
   "name": "flt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
